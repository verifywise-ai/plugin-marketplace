/**
 * Colorado Artificial Intelligence Act Framework Plugin (Bundled)
 * Generated by build-framework-plugins.js
 */

"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// plugins/colorado-ai-act/index.ts
var index_exports = {};
__export(index_exports, {
  install: () => install,
  metadata: () => metadata,
  router: () => router,
  uninstall: () => uninstall,
  validateConfig: () => validateConfig
});
module.exports = __toCommonJS(index_exports);

// packages/custom-framework-base/index.ts
async function ensureSharedTables(sequelize, tenantId) {
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_frameworks (
      id SERIAL PRIMARY KEY,
      plugin_key VARCHAR(100),
      name VARCHAR(255) NOT NULL,
      description TEXT,
      version VARCHAR(50) DEFAULT '1.0.0',
      is_organizational BOOLEAN DEFAULT FALSE,
      hierarchy_type VARCHAR(50) NOT NULL DEFAULT 'two_level',
      level_1_name VARCHAR(100) NOT NULL DEFAULT 'Category',
      level_2_name VARCHAR(100) NOT NULL DEFAULT 'Control',
      level_3_name VARCHAR(100),
      file_source VARCHAR(100),
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = '${tenantId}'
        AND table_name = 'custom_frameworks'
        AND column_name = 'plugin_key'
      ) THEN
        ALTER TABLE "${tenantId}".custom_frameworks ADD COLUMN plugin_key VARCHAR(100);
      END IF;
    END $$;
  `);
  await sequelize.query(`
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = '${tenantId}'
        AND table_name = 'custom_frameworks'
        AND column_name = 'file_source'
      ) THEN
        ALTER TABLE "${tenantId}".custom_frameworks ADD COLUMN file_source VARCHAR(100);
      END IF;
    END $$;
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level1 (
      id SERIAL PRIMARY KEY,
      framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_frameworks(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2 (
      id SERIAL PRIMARY KEY,
      level1_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level1(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      summary TEXT,
      questions TEXT[],
      evidence_examples TEXT[],
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3 (
      id SERIAL PRIMARY KEY,
      level2_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      summary TEXT,
      questions TEXT[],
      evidence_examples TEXT[],
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_projects (
      id SERIAL PRIMARY KEY,
      framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_frameworks(id) ON DELETE CASCADE,
      project_id INTEGER NOT NULL,
      created_at TIMESTAMP DEFAULT NOW(),
      UNIQUE(framework_id, project_id)
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2_impl (
      id SERIAL PRIMARY KEY,
      level2_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2(id) ON DELETE CASCADE,
      project_framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_projects(id) ON DELETE CASCADE,
      status VARCHAR(50) DEFAULT 'Not started',
      owner INTEGER,
      reviewer INTEGER,
      approver INTEGER,
      due_date DATE,
      implementation_details TEXT,
      evidence_links JSONB DEFAULT '[]',
      feedback_links JSONB DEFAULT '[]',
      auditor_feedback TEXT,
      is_demo BOOLEAN DEFAULT FALSE,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3_impl (
      id SERIAL PRIMARY KEY,
      level3_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level3(id) ON DELETE CASCADE,
      level2_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2_impl(id) ON DELETE CASCADE,
      status VARCHAR(50) DEFAULT 'Not started',
      owner INTEGER,
      reviewer INTEGER,
      approver INTEGER,
      due_date DATE,
      implementation_details TEXT,
      evidence_links JSONB DEFAULT '[]',
      feedback_links JSONB DEFAULT '[]',
      auditor_feedback TEXT,
      is_demo BOOLEAN DEFAULT FALSE,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2_risks (
      level2_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2_impl(id) ON DELETE CASCADE,
      risk_id INTEGER NOT NULL,
      PRIMARY KEY (level2_impl_id, risk_id)
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3_risks (
      level3_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level3_impl(id) ON DELETE CASCADE,
      risk_id INTEGER NOT NULL,
      PRIMARY KEY (level3_impl_id, risk_id)
    )
  `);
  const indexes = [
    `CREATE INDEX IF NOT EXISTS idx_cf_level1_framework ON "${tenantId}".custom_framework_level1(framework_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_level2_level1 ON "${tenantId}".custom_framework_level2(level1_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_level3_level2 ON "${tenantId}".custom_framework_level3(level2_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_l2impl_pf ON "${tenantId}".custom_framework_level2_impl(project_framework_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_l3impl_l2impl ON "${tenantId}".custom_framework_level3_impl(level2_impl_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_plugin_key ON "${tenantId}".custom_frameworks(plugin_key)`
  ];
  for (const idx of indexes) {
    await sequelize.query(idx);
  }
}
function toPgArray(arr) {
  if (!arr || arr.length === 0) return "{}";
  const escaped = arr.map((item) => {
    const escapedItem = String(item).replace(/\\/g, "\\\\").replace(/"/g, '\\"');
    return `"${escapedItem}"`;
  });
  return `{${escaped.join(",")}}`;
}
function generateFileSourceName(frameworkName) {
  const cleanName = frameworkName.trim();
  return `${cleanName} evidence`;
}
async function addFileSourceEnum(sequelize, sourceName) {
  try {
    const [existing] = await sequelize.query(
      `
      SELECT 1 FROM pg_enum
      WHERE enumtypid = (SELECT oid FROM pg_type WHERE typname = 'enum_files_source')
      AND enumlabel = :sourceName
    `,
      { replacements: { sourceName } }
    );
    if (existing.length === 0) {
      await sequelize.query(
        `ALTER TYPE public.enum_files_source ADD VALUE '${sourceName.replace(/'/g, "''")}'`
      );
      console.log(`[CustomFrameworkBase] Added file source enum: "${sourceName}"`);
    }
    return true;
  } catch (error) {
    console.error(`[CustomFrameworkBase] Failed to add file source enum: ${error.message}`);
    return false;
  }
}
async function importFramework(frameworkData, tenantId, sequelize, pluginKey) {
  const fileSource = generateFileSourceName(frameworkData.name);
  await addFileSourceEnum(sequelize, fileSource);
  const transaction = await sequelize.transaction();
  try {
    const [frameworkResult] = await sequelize.query(
      `INSERT INTO "${tenantId}".custom_frameworks
       (plugin_key, name, description, version, is_organizational, hierarchy_type, level_1_name, level_2_name, level_3_name, file_source, created_at)
       VALUES (:plugin_key, :name, :description, :version, :is_organizational, :hierarchy_type, :level_1_name, :level_2_name, :level_3_name, :file_source, NOW())
       RETURNING id`,
      {
        replacements: {
          plugin_key: pluginKey,
          name: frameworkData.name,
          description: frameworkData.description,
          version: frameworkData.version || "1.0.0",
          is_organizational: frameworkData.is_organizational,
          hierarchy_type: frameworkData.hierarchy.type,
          level_1_name: frameworkData.hierarchy.level1_name,
          level_2_name: frameworkData.hierarchy.level2_name,
          level_3_name: frameworkData.hierarchy.level3_name || null,
          file_source: fileSource
        },
        transaction
      }
    );
    const frameworkId = frameworkResult[0].id;
    let itemsCreated = 0;
    for (const level1 of frameworkData.structure) {
      const [level1Result] = await sequelize.query(
        `INSERT INTO "${tenantId}".custom_framework_level1
         (framework_id, title, description, order_no, metadata)
         VALUES (:framework_id, :title, :description, :order_no, :metadata)
         RETURNING id`,
        {
          replacements: {
            framework_id: frameworkId,
            title: level1.title,
            description: level1.description || null,
            order_no: level1.order_no,
            metadata: JSON.stringify(level1.metadata || {})
          },
          transaction
        }
      );
      const level1Id = level1Result[0].id;
      itemsCreated++;
      for (const level2 of level1.items || []) {
        const [level2Result] = await sequelize.query(
          `INSERT INTO "${tenantId}".custom_framework_level2
           (level1_id, title, description, order_no, summary, questions, evidence_examples, metadata)
           VALUES (:level1_id, :title, :description, :order_no, :summary, :questions, :evidence_examples, :metadata)
           RETURNING id`,
          {
            replacements: {
              level1_id: level1Id,
              title: level2.title,
              description: level2.description || null,
              order_no: level2.order_no,
              summary: level2.summary || null,
              questions: toPgArray(level2.questions),
              evidence_examples: toPgArray(level2.evidence_examples),
              metadata: JSON.stringify(level2.metadata || {})
            },
            transaction
          }
        );
        const level2Id = level2Result[0].id;
        itemsCreated++;
        if (frameworkData.hierarchy.type === "three_level" && level2.items) {
          for (const level3 of level2.items) {
            await sequelize.query(
              `INSERT INTO "${tenantId}".custom_framework_level3
               (level2_id, title, description, order_no, summary, questions, evidence_examples, metadata)
               VALUES (:level2_id, :title, :description, :order_no, :summary, :questions, :evidence_examples, :metadata)`,
              {
                replacements: {
                  level2_id: level2Id,
                  title: level3.title,
                  description: level3.description || null,
                  order_no: level3.order_no,
                  summary: level3.summary || null,
                  questions: toPgArray(level3.questions),
                  evidence_examples: toPgArray(level3.evidence_examples),
                  metadata: JSON.stringify(level3.metadata || {})
                },
                transaction
              }
            );
            itemsCreated++;
          }
        }
      }
    }
    await transaction.commit();
    return { frameworkId, itemsCreated, fileSource };
  } catch (error) {
    await transaction.rollback();
    throw error;
  }
}
function createRouteHandlers(pluginKey, config) {
  async function handleGetFrameworks(ctx) {
    const { sequelize, tenantId, query } = ctx;
    const showAll = query.all === "true";
    try {
      const whereClause = showAll ? "1=1" : "cf.plugin_key = :pluginKey OR cf.plugin_key IS NULL";
      const [frameworks] = await sequelize.query(
        `
        SELECT
          cf.id,
          cf.plugin_key,
          cf.name,
          cf.description,
          cf.version,
          cf.is_organizational,
          cf.hierarchy_type,
          cf.level_1_name,
          cf.level_2_name,
          cf.level_3_name,
          cf.file_source,
          cf.created_at,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level1 WHERE framework_id = cf.id) as level1_count,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level2 l2
           JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
           WHERE l1.framework_id = cf.id) as level2_count,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level3 l3
           JOIN "${tenantId}".custom_framework_level2 l2 ON l3.level2_id = l2.id
           JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
           WHERE l1.framework_id = cf.id) as level3_count
        FROM "${tenantId}".custom_frameworks cf
        WHERE ${whereClause}
        ORDER BY cf.created_at DESC
      `,
        { replacements: { pluginKey } }
      );
      return { status: 200, data: frameworks };
    } catch (error) {
      return { status: 500, data: { message: `Failed to fetch frameworks: ${error.message}` } };
    }
  }
  async function handleGetFrameworkById(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [meta] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (meta.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const [level1Items] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_framework_level1
         WHERE framework_id = :frameworkId ORDER BY order_no`,
        { replacements: { frameworkId } }
      );
      for (const l1 of level1Items) {
        const [level2Items] = await sequelize.query(
          `SELECT * FROM "${tenantId}".custom_framework_level2
           WHERE level1_id = :level1Id ORDER BY order_no`,
          { replacements: { level1Id: l1.id } }
        );
        for (const l2 of level2Items) {
          if (meta[0].hierarchy_type === "three_level") {
            const [level3Items] = await sequelize.query(
              `SELECT * FROM "${tenantId}".custom_framework_level3
               WHERE level2_id = :level2Id ORDER BY order_no`,
              { replacements: { level2Id: l2.id } }
            );
            l2.items = level3Items;
          }
        }
        l1.items = level2Items;
      }
      const [linkedProjectsRaw] = await sequelize.query(
        `SELECT
          cfp.id as project_framework_id,
          cfp.project_id,
          cfp.created_at as added_at,
          p.project_title,
          COALESCE(p.is_organizational, false) as is_organizational
        FROM "${tenantId}".custom_framework_projects cfp
        JOIN "${tenantId}".projects p ON cfp.project_id = p.id
        WHERE cfp.framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      const linkedProjects = await Promise.all(
        linkedProjectsRaw.map(async (proj) => {
          let progressData;
          if (meta[0].hierarchy_type === "three_level") {
            [progressData] = await sequelize.query(
              `SELECT
                COUNT(*) as total,
                SUM(CASE WHEN l3.status = 'Implemented' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN l3.owner IS NOT NULL THEN 1 ELSE 0 END) as assigned
              FROM "${tenantId}".custom_framework_level3_impl l3
              JOIN "${tenantId}".custom_framework_level2_impl l2 ON l3.level2_impl_id = l2.id
              WHERE l2.project_framework_id = :projectFrameworkId`,
              { replacements: { projectFrameworkId: proj.project_framework_id } }
            );
          } else {
            [progressData] = await sequelize.query(
              `SELECT
                COUNT(*) as total,
                SUM(CASE WHEN status = 'Implemented' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN owner IS NOT NULL THEN 1 ELSE 0 END) as assigned
              FROM "${tenantId}".custom_framework_level2_impl
              WHERE project_framework_id = :projectFrameworkId`,
              { replacements: { projectFrameworkId: proj.project_framework_id } }
            );
          }
          const total = parseInt(progressData[0]?.total || "0");
          const completed = parseInt(progressData[0]?.completed || "0");
          const assigned = parseInt(progressData[0]?.assigned || "0");
          return {
            project_framework_id: proj.project_framework_id,
            project_id: proj.project_id,
            project_title: proj.project_title,
            is_organizational: proj.is_organizational,
            added_at: proj.added_at,
            progress: {
              total,
              completed,
              assigned,
              percentage: total > 0 ? Math.round(completed / total * 100) : 0
            }
          };
        })
      );
      return {
        status: 200,
        data: {
          ...meta[0],
          structure: level1Items,
          linkedProjects
        }
      };
    } catch (error) {
      return { status: 500, data: { message: `Failed to fetch structure: ${error.message}` } };
    }
  }
  async function handleDeleteFramework(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [framework] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (framework.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const [projects] = await sequelize.query(
        `SELECT COUNT(*) as count FROM "${tenantId}".custom_framework_projects WHERE framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (parseInt(projects[0].count) > 0) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_projects WHERE framework_id = :frameworkId`,
          { replacements: { frameworkId } }
        );
      }
      await sequelize.query(`DELETE FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`, {
        replacements: { frameworkId }
      });
      return { status: 200, data: { success: true, message: "Framework deleted" } };
    } catch (error) {
      return { status: 500, data: { message: `Delete failed: ${error.message}` } };
    }
  }
  async function handleAddToProject(ctx) {
    const { sequelize, tenantId, body } = ctx;
    const { frameworkId, projectId } = body;
    if (!frameworkId || !projectId) {
      return { status: 400, data: { message: "frameworkId and projectId are required" } };
    }
    try {
      const [framework] = await sequelize.query(
        `SELECT id, hierarchy_type FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (framework.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const hierarchyType = framework[0].hierarchy_type;
      const [existing] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_projects
         WHERE framework_id = :frameworkId AND project_id = :projectId`,
        { replacements: { frameworkId, projectId } }
      );
      if (existing.length > 0) {
        return { status: 400, data: { message: "Framework already added to this project" } };
      }
      const [insertResult] = await sequelize.query(
        `INSERT INTO "${tenantId}".custom_framework_projects (framework_id, project_id, created_at)
         VALUES (:frameworkId, :projectId, NOW())
         RETURNING id`,
        { replacements: { frameworkId, projectId } }
      );
      const projectFrameworkId = insertResult[0].id;
      const [level2Items] = await sequelize.query(
        `SELECT l2.id FROM "${tenantId}".custom_framework_level2 l2
         JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
         WHERE l1.framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      for (const l2 of level2Items) {
        const [implResult] = await sequelize.query(
          `INSERT INTO "${tenantId}".custom_framework_level2_impl
           (level2_id, project_framework_id, status, created_at, updated_at)
           VALUES (:level2_id, :project_framework_id, 'Not started', NOW(), NOW())
           RETURNING id`,
          { replacements: { level2_id: l2.id, project_framework_id: projectFrameworkId } }
        );
        if (hierarchyType === "three_level") {
          const [level3Items] = await sequelize.query(
            `SELECT id FROM "${tenantId}".custom_framework_level3 WHERE level2_id = :level2Id`,
            { replacements: { level2Id: l2.id } }
          );
          for (const l3 of level3Items) {
            await sequelize.query(
              `INSERT INTO "${tenantId}".custom_framework_level3_impl
               (level3_id, level2_impl_id, status, created_at, updated_at)
               VALUES (:level3_id, :level2_impl_id, 'Not started', NOW(), NOW())`,
              { replacements: { level3_id: l3.id, level2_impl_id: implResult[0].id } }
            );
          }
        }
      }
      return {
        status: 200,
        data: { success: true, message: "Framework added to project", projectFrameworkId }
      };
    } catch (error) {
      return { status: 500, data: { message: `Failed to add: ${error.message}` } };
    }
  }
  async function handleRemoveFromProject(ctx) {
    const { sequelize, tenantId, body } = ctx;
    const { frameworkId, projectId } = body;
    if (!frameworkId || !projectId) {
      return { status: 400, data: { message: "frameworkId and projectId are required" } };
    }
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".custom_framework_projects
         WHERE framework_id = :frameworkId AND project_id = :projectId`,
        { replacements: { frameworkId, projectId } }
      );
      return { status: 200, data: { success: true, message: "Framework removed from project" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to remove: ${error.message}` } };
    }
  }
  async function handleGetProjectFrameworks(ctx) {
    const { sequelize, tenantId, params, query } = ctx;
    const projectId = parseInt(params.projectId);
    const isOrganizational = query.is_organizational === "true";
    try {
      const [frameworks] = await sequelize.query(
        `
        SELECT cf.*, cf.id as framework_id, cfp.id as project_framework_id, cfp.created_at as added_at
        FROM "${tenantId}".custom_frameworks cf
        JOIN "${tenantId}".custom_framework_projects cfp ON cf.id = cfp.framework_id
        WHERE cfp.project_id = :projectId
        ORDER BY cf.name
      `,
        { replacements: { projectId } }
      );
      return { status: 200, data: frameworks };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleGetProjectFramework(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const projectId = parseInt(params.projectId);
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [projectFramework] = await sequelize.query(
        `SELECT cfp.id as project_framework_id, cf.*
         FROM "${tenantId}".custom_framework_projects cfp
         JOIN "${tenantId}".custom_frameworks cf ON cfp.framework_id = cf.id
         WHERE cfp.project_id = :projectId AND cfp.framework_id = :frameworkId`,
        { replacements: { projectId, frameworkId } }
      );
      if (projectFramework.length === 0) {
        return { status: 404, data: { message: "Framework not found in project" } };
      }
      const pf = projectFramework[0];
      const projectFrameworkId = pf.project_framework_id;
      const [level1Items] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_framework_level1
         WHERE framework_id = :frameworkId ORDER BY order_no`,
        { replacements: { frameworkId } }
      );
      for (const l1 of level1Items) {
        const [level2Items] = await sequelize.query(
          `SELECT l2.*,
                  impl.id as impl_id, impl.status, impl.owner, impl.reviewer, impl.approver,
                  impl.due_date, impl.implementation_details, impl.evidence_links,
                  impl.feedback_links, impl.auditor_feedback,
                  u_owner.name as owner_name, u_owner.surname as owner_surname,
                  u_reviewer.name as reviewer_name, u_reviewer.surname as reviewer_surname,
                  u_approver.name as approver_name, u_approver.surname as approver_surname
           FROM "${tenantId}".custom_framework_level2 l2
           LEFT JOIN "${tenantId}".custom_framework_level2_impl impl
             ON l2.id = impl.level2_id AND impl.project_framework_id = :projectFrameworkId
           LEFT JOIN public.users u_owner ON impl.owner = u_owner.id
           LEFT JOIN public.users u_reviewer ON impl.reviewer = u_reviewer.id
           LEFT JOIN public.users u_approver ON impl.approver = u_approver.id
           WHERE l2.level1_id = :level1Id
           ORDER BY l2.order_no`,
          { replacements: { level1Id: l1.id, projectFrameworkId } }
        );
        for (const l2 of level2Items) {
          if (l2.impl_id) {
            const [risks] = await sequelize.query(
              `SELECT r.id, r.risk_name, r.risk_description
               FROM "${tenantId}".custom_framework_level2_risks lr
               JOIN "${tenantId}".risks r ON lr.risk_id = r.id
               WHERE lr.level2_impl_id = :implId`,
              { replacements: { implId: l2.impl_id } }
            );
            l2.linked_risks = risks;
            const [linkedFiles] = await sequelize.query(
              `SELECT
                f.id,
                f.filename,
                f.size,
                f.type as mimetype,
                f.uploaded_time as upload_date,
                u.name as uploader_name,
                u.surname as uploader_surname,
                fel.link_type
              FROM "${tenantId}".file_entity_links fel
              JOIN "${tenantId}".files f ON fel.file_id = f.id
              LEFT JOIN public.users u ON f.uploaded_by = u.id
              WHERE fel.framework_type = :frameworkType
                AND fel.entity_type = 'level2_impl'
                AND fel.entity_id = :implId
              ORDER BY fel.created_at DESC`,
              { replacements: { frameworkType: pluginKey, implId: l2.impl_id } }
            );
            l2.linked_files = linkedFiles;
          } else {
            l2.linked_risks = [];
            l2.linked_files = [];
          }
          if (pf.hierarchy_type === "three_level") {
            const [level3Items] = await sequelize.query(
              `SELECT l3.*,
                      impl.id as impl_id, impl.status, impl.owner, impl.reviewer, impl.approver,
                      impl.due_date, impl.implementation_details, impl.evidence_links
               FROM "${tenantId}".custom_framework_level3 l3
               LEFT JOIN "${tenantId}".custom_framework_level3_impl impl
                 ON l3.id = impl.level3_id AND impl.level2_impl_id = :level2ImplId
               WHERE l3.level2_id = :level2Id
               ORDER BY l3.order_no`,
              { replacements: { level2Id: l2.id, level2ImplId: l2.impl_id } }
            );
            for (const l3 of level3Items) {
              if (l3.impl_id) {
                const [l3Files] = await sequelize.query(
                  `SELECT
                    f.id,
                    f.filename,
                    f.size,
                    f.type as mimetype,
                    f.uploaded_time as upload_date,
                    u.name as uploader_name,
                    u.surname as uploader_surname,
                    fel.link_type
                  FROM "${tenantId}".file_entity_links fel
                  JOIN "${tenantId}".files f ON fel.file_id = f.id
                  LEFT JOIN public.users u ON f.uploaded_by = u.id
                  WHERE fel.framework_type = :frameworkType
                    AND fel.entity_type = 'level3_impl'
                    AND fel.entity_id = :implId
                  ORDER BY fel.created_at DESC`,
                  { replacements: { frameworkType: pluginKey, implId: l3.impl_id } }
                );
                l3.linked_files = l3Files;
              } else {
                l3.linked_files = [];
              }
            }
            l2.items = level3Items;
          }
        }
        l1.items = level2Items;
      }
      return {
        status: 200,
        data: {
          projectFrameworkId,
          frameworkId: pf.id,
          name: pf.name,
          description: pf.description,
          is_organizational: pf.is_organizational,
          hierarchy_type: pf.hierarchy_type,
          level_1_name: pf.level_1_name,
          level_2_name: pf.level_2_name,
          level_3_name: pf.level_3_name,
          file_source: pf.file_source,
          structure: level1Items
        }
      };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleGetProgress(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const projectId = parseInt(params.projectId);
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [projectFramework] = await sequelize.query(
        `SELECT cfp.id as project_framework_id, cf.hierarchy_type
         FROM "${tenantId}".custom_framework_projects cfp
         JOIN "${tenantId}".custom_frameworks cf ON cfp.framework_id = cf.id
         WHERE cfp.project_id = :projectId AND cfp.framework_id = :frameworkId`,
        { replacements: { projectId, frameworkId } }
      );
      if (projectFramework.length === 0) {
        return { status: 404, data: { message: "Framework not found in project" } };
      }
      const projectFrameworkId = projectFramework[0].project_framework_id;
      const hierarchyType = projectFramework[0].hierarchy_type;
      const [level2Stats] = await sequelize.query(
        `SELECT
           COUNT(*) as total,
           COUNT(CASE WHEN status = 'Implemented' THEN 1 END) as completed,
           COUNT(CASE WHEN owner IS NOT NULL THEN 1 END) as assigned
         FROM "${tenantId}".custom_framework_level2_impl
         WHERE project_framework_id = :projectFrameworkId`,
        { replacements: { projectFrameworkId } }
      );
      const result = {
        level2: {
          total: parseInt(level2Stats[0].total),
          completed: parseInt(level2Stats[0].completed),
          assigned: parseInt(level2Stats[0].assigned),
          percentage: parseInt(level2Stats[0].total) > 0 ? Math.round(
            parseInt(level2Stats[0].completed) / parseInt(level2Stats[0].total) * 100
          ) : 0
        }
      };
      if (hierarchyType === "three_level") {
        const [level3Stats] = await sequelize.query(
          `SELECT
             COUNT(*) as total,
             COUNT(CASE WHEN l3.status = 'Implemented' THEN 1 END) as completed,
             COUNT(CASE WHEN l3.owner IS NOT NULL THEN 1 END) as assigned
           FROM "${tenantId}".custom_framework_level3_impl l3
           JOIN "${tenantId}".custom_framework_level2_impl l2 ON l3.level2_impl_id = l2.id
           WHERE l2.project_framework_id = :projectFrameworkId`,
          { replacements: { projectFrameworkId } }
        );
        result.level3 = {
          total: parseInt(level3Stats[0].total),
          completed: parseInt(level3Stats[0].completed),
          assigned: parseInt(level3Stats[0].assigned),
          percentage: parseInt(level3Stats[0].total) > 0 ? Math.round(
            parseInt(level3Stats[0].completed) / parseInt(level3Stats[0].total) * 100
          ) : 0
        };
        result.overall = result.level3;
      } else {
        result.overall = result.level2;
      }
      return { status: 200, data: result };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleUpdateLevel2(ctx) {
    const { sequelize, tenantId, params, body } = ctx;
    const implId = parseInt(params.level2Id);
    try {
      const updateFields = [];
      const replacements = { id: implId };
      const allowedFields = [
        "status",
        "owner",
        "reviewer",
        "approver",
        "due_date",
        "implementation_details",
        "evidence_links",
        "feedback_links",
        "auditor_feedback"
      ];
      for (const field of allowedFields) {
        if (body[field] !== void 0) {
          if (field === "evidence_links" || field === "feedback_links") {
            updateFields.push(`${field} = :${field}::jsonb`);
            replacements[field] = JSON.stringify(body[field]);
          } else if (field === "due_date" && body[field] === null) {
            updateFields.push(`${field} = NULL`);
          } else {
            updateFields.push(`${field} = :${field}`);
            replacements[field] = body[field];
          }
        }
      }
      if (updateFields.length === 0) {
        return { status: 400, data: { message: "No fields to update" } };
      }
      updateFields.push("updated_at = NOW()");
      await sequelize.query(
        `UPDATE "${tenantId}".custom_framework_level2_impl
         SET ${updateFields.join(", ")}
         WHERE id = :id`,
        { replacements }
      );
      if (body.risks_to_add && Array.isArray(body.risks_to_add)) {
        for (const riskId of body.risks_to_add) {
          await sequelize.query(
            `INSERT INTO "${tenantId}".custom_framework_level2_risks (level2_impl_id, risk_id)
             VALUES (:implId, :riskId)
             ON CONFLICT DO NOTHING`,
            { replacements: { implId, riskId } }
          );
        }
      }
      if (body.risks_to_remove && Array.isArray(body.risks_to_remove)) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_level2_risks
           WHERE level2_impl_id = :implId AND risk_id = ANY(:risks)`,
          { replacements: { implId, risks: body.risks_to_remove } }
        );
      }
      return { status: 200, data: { success: true, message: "Updated successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Update failed: ${error.message}` } };
    }
  }
  async function handleUpdateLevel3(ctx) {
    const { sequelize, tenantId, params, body } = ctx;
    const implId = parseInt(params.level3Id);
    try {
      const updateFields = [];
      const replacements = { id: implId };
      const allowedFields = [
        "status",
        "owner",
        "reviewer",
        "approver",
        "due_date",
        "implementation_details",
        "evidence_links",
        "feedback_links",
        "auditor_feedback"
      ];
      for (const field of allowedFields) {
        if (body[field] !== void 0) {
          if (field === "evidence_links" || field === "feedback_links") {
            updateFields.push(`${field} = :${field}::jsonb`);
            replacements[field] = JSON.stringify(body[field]);
          } else if (field === "due_date" && body[field] === null) {
            updateFields.push(`${field} = NULL`);
          } else {
            updateFields.push(`${field} = :${field}`);
            replacements[field] = body[field];
          }
        }
      }
      if (updateFields.length === 0) {
        return { status: 400, data: { message: "No fields to update" } };
      }
      updateFields.push("updated_at = NOW()");
      await sequelize.query(
        `UPDATE "${tenantId}".custom_framework_level3_impl
         SET ${updateFields.join(", ")}
         WHERE id = :id`,
        { replacements }
      );
      return { status: 200, data: { success: true, message: "Updated successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Update failed: ${error.message}` } };
    }
  }
  async function handleAttachFilesToLevel2(ctx) {
    const { sequelize, tenantId, userId, params, body } = ctx;
    const implId = parseInt(params.level2Id);
    const { file_ids, link_type = "evidence" } = body;
    if (!file_ids || !Array.isArray(file_ids) || file_ids.length === 0) {
      return { status: 400, data: { message: "file_ids array is required" } };
    }
    try {
      const [impl] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_level2_impl WHERE id = :implId`,
        { replacements: { implId } }
      );
      if (impl.length === 0) {
        return { status: 404, data: { message: "Implementation record not found" } };
      }
      const results = [];
      for (const fileId of file_ids) {
        try {
          await sequelize.query(
            `INSERT INTO "${tenantId}".file_entity_links
             (file_id, framework_type, entity_type, entity_id, link_type, created_by, created_at)
             VALUES (:fileId, :frameworkType, 'level2_impl', :entityId, :linkType, :userId, NOW())
             ON CONFLICT (file_id, framework_type, entity_type, entity_id) DO NOTHING`,
            {
              replacements: {
                fileId,
                frameworkType: pluginKey,
                entityId: implId,
                linkType: link_type,
                userId
              }
            }
          );
          results.push({ file_id: fileId, success: true, message: "Attached" });
        } catch (err) {
          results.push({ file_id: fileId, success: false, message: err.message });
        }
      }
      return { status: 200, data: { message: "Files attached", results } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to attach files: ${error.message}` } };
    }
  }
  async function handleGetLevel2Files(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level2Id);
    try {
      const [files] = await sequelize.query(
        `SELECT
          f.id,
          f.filename,
          f.size,
          f.type as mimetype,
          f.uploaded_time as upload_date,
          f.uploaded_by,
          u.name as uploader_name,
          u.surname as uploader_surname,
          fel.link_type,
          fel.created_at as linked_at
        FROM "${tenantId}".file_entity_links fel
        JOIN "${tenantId}".files f ON fel.file_id = f.id
        LEFT JOIN public.users u ON f.uploaded_by = u.id
        WHERE fel.framework_type = :frameworkType
          AND fel.entity_type = 'level2_impl'
          AND fel.entity_id = :entityId
        ORDER BY fel.created_at DESC`,
        {
          replacements: {
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: files };
    } catch (error) {
      return { status: 500, data: { message: `Failed to get files: ${error.message}` } };
    }
  }
  async function handleDetachFileFromLevel2(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level2Id);
    const fileId = parseInt(params.fileId);
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".file_entity_links
         WHERE file_id = :fileId
           AND framework_type = :frameworkType
           AND entity_type = 'level2_impl'
           AND entity_id = :entityId`,
        {
          replacements: {
            fileId,
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: { message: "File detached successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to detach file: ${error.message}` } };
    }
  }
  async function handleAttachFilesToLevel3(ctx) {
    const { sequelize, tenantId, userId, params, body } = ctx;
    const implId = parseInt(params.level3Id);
    const { file_ids, link_type = "evidence" } = body;
    if (!file_ids || !Array.isArray(file_ids) || file_ids.length === 0) {
      return { status: 400, data: { message: "file_ids array is required" } };
    }
    try {
      const [impl] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_level3_impl WHERE id = :implId`,
        { replacements: { implId } }
      );
      if (impl.length === 0) {
        return { status: 404, data: { message: "Implementation record not found" } };
      }
      const results = [];
      for (const fileId of file_ids) {
        try {
          await sequelize.query(
            `INSERT INTO "${tenantId}".file_entity_links
             (file_id, framework_type, entity_type, entity_id, link_type, created_by, created_at)
             VALUES (:fileId, :frameworkType, 'level3_impl', :entityId, :linkType, :userId, NOW())
             ON CONFLICT (file_id, framework_type, entity_type, entity_id) DO NOTHING`,
            {
              replacements: {
                fileId,
                frameworkType: pluginKey,
                entityId: implId,
                linkType: link_type,
                userId
              }
            }
          );
          results.push({ file_id: fileId, success: true, message: "Attached" });
        } catch (err) {
          results.push({ file_id: fileId, success: false, message: err.message });
        }
      }
      return { status: 200, data: { message: "Files attached", results } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to attach files: ${error.message}` } };
    }
  }
  async function handleGetLevel3Files(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level3Id);
    try {
      const [files] = await sequelize.query(
        `SELECT
          f.id,
          f.filename,
          f.size,
          f.type as mimetype,
          f.uploaded_time as upload_date,
          f.uploaded_by,
          u.name as uploader_name,
          u.surname as uploader_surname,
          fel.link_type,
          fel.created_at as linked_at
        FROM "${tenantId}".file_entity_links fel
        JOIN "${tenantId}".files f ON fel.file_id = f.id
        LEFT JOIN public.users u ON f.uploaded_by = u.id
        WHERE fel.framework_type = :frameworkType
          AND fel.entity_type = 'level3_impl'
          AND fel.entity_id = :entityId
        ORDER BY fel.created_at DESC`,
        {
          replacements: {
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: files };
    } catch (error) {
      return { status: 500, data: { message: `Failed to get files: ${error.message}` } };
    }
  }
  async function handleDetachFileFromLevel3(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level3Id);
    const fileId = parseInt(params.fileId);
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".file_entity_links
         WHERE file_id = :fileId
           AND framework_type = :frameworkType
           AND entity_type = 'level3_impl'
           AND entity_id = :entityId`,
        {
          replacements: {
            fileId,
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: { message: "File detached successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to detach file: ${error.message}` } };
    }
  }
  return {
    handleGetFrameworks,
    handleGetFrameworkById,
    handleDeleteFramework,
    handleAddToProject,
    handleRemoveFromProject,
    handleGetProjectFrameworks,
    handleGetProjectFramework,
    handleGetProgress,
    handleUpdateLevel2,
    handleUpdateLevel3,
    // File attachment handlers
    handleAttachFilesToLevel2,
    handleGetLevel2Files,
    handleDetachFileFromLevel2,
    handleAttachFilesToLevel3,
    handleGetLevel3Files,
    handleDetachFileFromLevel3
  };
}
function createFrameworkPlugin(config) {
  const pluginKey = config.key;
  const metadata2 = {
    name: config.name,
    version: config.version || "1.0.0",
    author: config.author || "VerifyWise",
    description: config.description
  };
  async function install2(_userId, tenantId, _config, context) {
    const { sequelize } = context;
    try {
      await ensureSharedTables(sequelize, tenantId);
      if (config.autoImport !== false && config.template) {
        const [existing] = await sequelize.query(
          `SELECT id FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
          { replacements: { pluginKey } }
        );
        if (existing.length === 0) {
          const result = await importFramework(config.template, tenantId, sequelize, pluginKey);
          console.log(
            `[${config.name}] Auto-imported framework with ${result.itemsCreated} items`
          );
        }
      }
      return {
        success: true,
        message: `${config.name} plugin installed successfully.`,
        installedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
    } catch (error) {
      throw new Error(`Installation failed: ${error.message}`);
    }
  }
  async function uninstall2(_userId, tenantId, context) {
    const { sequelize } = context;
    try {
      const [frameworks] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
        { replacements: { pluginKey } }
      );
      const frameworkIds = frameworks.map((f) => f.id);
      if (frameworkIds.length > 0) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_projects WHERE framework_id IN (:ids)`,
          { replacements: { ids: frameworkIds } }
        );
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
          { replacements: { pluginKey } }
        );
      }
      return {
        success: true,
        message: `${config.name} plugin uninstalled successfully.`,
        uninstalledAt: (/* @__PURE__ */ new Date()).toISOString()
      };
    } catch (error) {
      throw new Error(`Uninstall failed: ${error.message}`);
    }
  }
  function validateConfig2(_config) {
    return { valid: true, errors: [] };
  }
  const handlers = createRouteHandlers(pluginKey, config);
  const router2 = {
    "GET /frameworks": handlers.handleGetFrameworks,
    "GET /frameworks/:frameworkId": handlers.handleGetFrameworkById,
    "DELETE /frameworks/:frameworkId": handlers.handleDeleteFramework,
    "POST /add-to-project": handlers.handleAddToProject,
    "POST /remove-from-project": handlers.handleRemoveFromProject,
    "GET /projects/:projectId/custom-frameworks": handlers.handleGetProjectFrameworks,
    "GET /projects/:projectId/frameworks/:frameworkId": handlers.handleGetProjectFramework,
    "GET /projects/:projectId/frameworks/:frameworkId/progress": handlers.handleGetProgress,
    "PATCH /level2/:level2Id": handlers.handleUpdateLevel2,
    "PATCH /level3/:level3Id": handlers.handleUpdateLevel3,
    // File attachment routes for level2 implementations
    "POST /level2/:level2Id/files": handlers.handleAttachFilesToLevel2,
    "GET /level2/:level2Id/files": handlers.handleGetLevel2Files,
    "DELETE /level2/:level2Id/files/:fileId": handlers.handleDetachFileFromLevel2,
    // File attachment routes for level3 implementations
    "POST /level3/:level3Id/files": handlers.handleAttachFilesToLevel3,
    "GET /level3/:level3Id/files": handlers.handleGetLevel3Files,
    "DELETE /level3/:level3Id/files/:fileId": handlers.handleDetachFileFromLevel3
  };
  return {
    metadata: metadata2,
    install: install2,
    uninstall: uninstall2,
    validateConfig: validateConfig2,
    router: router2
  };
}

// plugins/colorado-ai-act/template.json
var template_default = {
  id: "colorado-ai-act",
  name: "Colorado Artificial Intelligence Act",
  description: "Colorado AI Act compliance framework for preventing algorithmic discrimination in high-risk AI systems.",
  category: "AI Governance",
  tags: ["Colorado", "AI Act", "Algorithmic Discrimination", "AI Governance", "United States", "High-Risk AI"],
  framework: {
    name: "Colorado Artificial Intelligence Act Framework",
    description: "Framework for ensuring compliance with the Colorado Artificial Intelligence Act (SB 21-169) which aims to protect consumers from algorithmic discrimination in high-risk AI decision-making",
    version: "1.0.0",
    is_organizational: false,
    hierarchy: {
      type: "two_level",
      level1_name: "Chapter",
      level2_name: "Section"
    },
    structure: [
      {
        title: "Chapter 1: Scope and Definitions",
        description: "Applicability, key definitions, and determination of high-risk AI systems under Colorado AI Act",
        order_no: 1,
        items: [
          {
            title: "Sec. 1.1 - High-Risk AI System Determination",
            description: "Determine whether AI systems qualify as high-risk under the Colorado AI Act",
            order_no: 1,
            summary: "High-risk AI systems are those that make or are substantial factors in consequential decisions concerning consumers in: education, employment, financial services, government services, healthcare, housing, insurance, and legal services",
            questions: [
              "Does the AI system make or substantially factor into consequential decisions?",
              "Are decisions made in covered domains (education, employment, financial, etc.)?",
              "Does the system affect consumer access to services or opportunities?",
              "Is the AI a substantial factor in the decision-making process?"
            ],
            evidence_examples: [
              "AI system inventory with risk classification",
              "Consequential decision analysis",
              "Domain applicability assessment",
              "Substantial factor determination"
            ]
          },
          {
            title: "Sec. 1.2 - Developer and Deployer Classification",
            description: "Classify your organization's role as developer, deployer, or both",
            order_no: 2,
            summary: "Developers create or substantially modify AI systems. Deployers use AI systems for consequential decisions. Many organizations serve both roles. Each role has distinct compliance obligations",
            questions: [
              "Does your organization develop or substantially modify AI systems?",
              "Does your organization deploy AI for consequential decisions?",
              "Are both developer and deployer obligations applicable?",
              "Are third-party developers properly managed?"
            ],
            evidence_examples: [
              "Role classification documentation",
              "Developer/deployer responsibility matrix",
              "Third-party developer inventory",
              "Obligation mapping by role"
            ]
          },
          {
            title: "Sec. 1.3 - Algorithmic Discrimination Definition",
            description: "Understand what constitutes algorithmic discrimination under the Act",
            order_no: 3,
            summary: "Algorithmic discrimination means differential treatment or impact that disfavors an individual or group based on: age, color, disability, ethnicity, genetic information, national origin, race, religion, reproductive health, sex, veteran status, or other protected characteristics",
            questions: [
              "Are all protected characteristics identified?",
              "Is there understanding of differential treatment vs. disparate impact?",
              "Are discrimination testing protocols established?",
              "Is there process to identify potential discrimination?"
            ],
            evidence_examples: [
              "Protected characteristic inventory",
              "Discrimination definition documentation",
              "Testing protocol for discrimination",
              "Legal interpretation guidance"
            ]
          },
          {
            title: "Sec. 1.4 - Exemptions and Exceptions",
            description: "Identify applicable exemptions from the Colorado AI Act",
            order_no: 4,
            summary: "Certain uses may be exempt including: narrow AI for specific administrative tasks, AI used solely for data processing without decision-making, federally regulated AI in certain contexts, and AI used for national security",
            questions: [
              "Are any AI systems potentially exempt?",
              "Is exemption analysis documented?",
              "Are exempt systems still monitored for scope changes?",
              "Is legal review obtained for exemption claims?"
            ],
            evidence_examples: [
              "Exemption analysis documentation",
              "Legal review of exemptions",
              "Scope monitoring procedures",
              "Exemption justification records"
            ]
          }
        ]
      },
      {
        title: "Chapter 2: Developer Duties",
        description: "Obligations for developers of high-risk AI systems",
        order_no: 2,
        items: [
          {
            title: "Sec. 2.1 - Reasonable Care Standard",
            description: "Exercise reasonable care to protect consumers from algorithmic discrimination",
            order_no: 1,
            summary: "Developers must use reasonable care to protect consumers from known or reasonably foreseeable risks of algorithmic discrimination. This is the overarching duty that informs all other developer obligations",
            questions: [
              "Is there a documented approach to reasonable care?",
              "Are discrimination risks identified and assessed?",
              "Are mitigation measures implemented?",
              "Is the approach regularly reviewed and updated?"
            ],
            evidence_examples: [
              "Reasonable care policy",
              "Risk identification procedures",
              "Mitigation measure documentation",
              "Review and update records"
            ]
          },
          {
            title: "Sec. 2.2 - Documentation for Deployers",
            description: "Provide required documentation to deployers of AI systems",
            order_no: 2,
            summary: "Developers must provide deployers with: general description of system and capabilities, documentation of training data, known limitations, intended uses and foreseeable misuses, and information needed for impact assessments",
            questions: [
              "Is comprehensive documentation provided to deployers?",
              "Does documentation include training data information?",
              "Are limitations and intended uses documented?",
              "Is documentation sufficient for deployer impact assessments?"
            ],
            evidence_examples: [
              "Deployer documentation package",
              "Training data documentation",
              "Limitation disclosures",
              "Intended use documentation"
            ]
          },
          {
            title: "Sec. 2.3 - Public Disclosure Statement",
            description: "Make public statement regarding high-risk AI systems",
            order_no: 3,
            summary: "Developers must make publicly available a statement describing: types of high-risk AI systems developed, how the developer manages discrimination risks, and the nature of the documentation provided to deployers",
            questions: [
              "Is public statement published and accessible?",
              "Does statement describe high-risk AI types?",
              "Is risk management approach described?",
              "Is documentation practice disclosed?"
            ],
            evidence_examples: [
              "Public disclosure statement",
              "Website publication",
              "Statement update records",
              "Accessibility verification"
            ]
          },
          {
            title: "Sec. 2.4 - Known Discrimination Disclosure",
            description: "Disclose known or reasonably foreseeable discrimination risks",
            order_no: 4,
            summary: "Developers must disclose to deployers and the Attorney General any known or reasonably foreseeable risks of algorithmic discrimination, including risks discovered after deployment",
            questions: [
              "Is there process for identifying discrimination risks?",
              "Are known risks disclosed to deployers?",
              "Is Attorney General notified of significant risks?",
              "Are post-deployment discoveries reported?"
            ],
            evidence_examples: [
              "Risk identification process",
              "Deployer disclosure records",
              "AG notification records",
              "Post-deployment disclosure procedures"
            ]
          },
          {
            title: "Sec. 2.5 - Attorney General Cooperation",
            description: "Cooperate with Attorney General investigations and requests",
            order_no: 5,
            summary: "Developers must cooperate with the Attorney General in investigations, provide requested documentation and information, and respond to inquiries in a timely manner",
            questions: [
              "Is there process for AG inquiry response?",
              "Can requested documentation be produced?",
              "Is there designated contact for AG matters?",
              "Are response timelines established?"
            ],
            evidence_examples: [
              "AG cooperation procedures",
              "Document production capability",
              "Designated contact information",
              "Response timeline documentation"
            ]
          }
        ]
      },
      {
        title: "Chapter 3: Deployer Duties",
        description: "Obligations for deployers of high-risk AI systems",
        order_no: 3,
        items: [
          {
            title: "Sec. 3.1 - Risk Management Policy and Program",
            description: "Implement risk management policy and program for high-risk AI",
            order_no: 1,
            summary: "Deployers must implement a risk management policy and program to govern deployment of high-risk AI. The program must be reasonable and proportionate to the nature and size of the deployer and scope of AI use",
            questions: [
              "Is there documented risk management policy?",
              "Is program proportionate to organization size?",
              "Does program cover all high-risk AI systems?",
              "Is the program regularly reviewed?"
            ],
            evidence_examples: [
              "Risk management policy",
              "Program documentation",
              "Proportionality assessment",
              "Program review records"
            ]
          },
          {
            title: "Sec. 3.2 - Impact Assessment Requirement",
            description: "Complete impact assessments for high-risk AI systems",
            order_no: 2,
            summary: "Deployers must complete impact assessments before deploying high-risk AI and annually thereafter. Assessments must evaluate: purpose and intended use, data and algorithms, discrimination risks, and mitigation measures",
            questions: [
              "Are impact assessments completed before deployment?",
              "Are assessments updated annually?",
              "Do assessments cover all required elements?",
              "Are assessments documented and retained?"
            ],
            evidence_examples: [
              "Impact assessment templates",
              "Completed assessments",
              "Annual review schedule",
              "Assessment retention records"
            ]
          },
          {
            title: "Sec. 3.3 - Consumer Notification",
            description: "Notify consumers about AI use in consequential decisions",
            order_no: 3,
            summary: "Deployers must notify consumers that a high-risk AI system is being used to make or substantially contribute to a consequential decision. Notification must be provided before or at the time of the decision",
            questions: [
              "Are consumers notified of AI use?",
              "Is notification timely (before or at decision)?",
              "Is notification clear and understandable?",
              "Are notification methods documented?"
            ],
            evidence_examples: [
              "Consumer notification procedures",
              "Sample notifications",
              "Timing verification",
              "Notification delivery records"
            ]
          },
          {
            title: "Sec. 3.4 - Explanation Statement",
            description: "Provide statement explaining AI's role in adverse decisions",
            order_no: 4,
            summary: "For adverse decisions, deployers must provide consumers with a statement explaining: the principal reasons for the decision, the role of the AI system, the type of data used, and how to appeal or contest the decision",
            questions: [
              "Are explanation statements provided for adverse decisions?",
              "Do statements include principal reasons?",
              "Is AI's role clearly explained?",
              "Is appeal information included?"
            ],
            evidence_examples: [
              "Explanation statement templates",
              "Sample explanation statements",
              "Appeal process documentation",
              "Statement delivery records"
            ]
          },
          {
            title: "Sec. 3.5 - Appeal and Correction Process",
            description: "Provide opportunity to appeal or correct AI-influenced decisions",
            order_no: 5,
            summary: "Deployers must provide consumers opportunity to appeal adverse decisions, correct inaccurate data used in the decision, and request human review. Appeal process must be accessible and timely",
            questions: [
              "Is appeal process established and documented?",
              "Can consumers correct inaccurate data?",
              "Is human review available?",
              "Is appeal process accessible and timely?"
            ],
            evidence_examples: [
              "Appeal process documentation",
              "Data correction procedures",
              "Human review procedures",
              "Appeal response timelines"
            ]
          },
          {
            title: "Sec. 3.6 - Public Disclosure Statement",
            description: "Publish public statement about high-risk AI use",
            order_no: 6,
            summary: "Deployers must make publicly available a statement describing: types of high-risk AI systems deployed, how risks of algorithmic discrimination are managed, and contact information for consumer inquiries",
            questions: [
              "Is public statement published?",
              "Does statement describe AI systems used?",
              "Is risk management approach disclosed?",
              "Is contact information provided?"
            ],
            evidence_examples: [
              "Public disclosure statement",
              "Website publication",
              "Contact information",
              "Statement update records"
            ]
          }
        ]
      },
      {
        title: "Chapter 4: Algorithmic Discrimination Prevention",
        description: "Measures to prevent, detect, and remediate algorithmic discrimination",
        order_no: 4,
        items: [
          {
            title: "Sec. 4.1 - Bias Testing and Evaluation",
            description: "Conduct testing to identify potential algorithmic discrimination",
            order_no: 1,
            summary: "Implement testing protocols to identify potential discrimination based on protected characteristics. Testing should occur before deployment and periodically thereafter",
            questions: [
              "Is bias testing conducted before deployment?",
              "Are all protected characteristics tested?",
              "Is testing conducted periodically?",
              "Are testing results documented?"
            ],
            evidence_examples: [
              "Bias testing methodology",
              "Testing results documentation",
              "Protected characteristic coverage",
              "Testing schedule"
            ]
          },
          {
            title: "Sec. 4.2 - Training Data Assessment",
            description: "Assess training data for bias and representativeness",
            order_no: 2,
            summary: "Evaluate training data sources, quality, and representativeness. Identify and address potential biases embedded in training data that could lead to discriminatory outcomes",
            questions: [
              "Is training data assessed for bias?",
              "Is data representativeness evaluated?",
              "Are data sources vetted for quality?",
              "Are identified biases addressed?"
            ],
            evidence_examples: [
              "Training data assessment",
              "Representativeness analysis",
              "Data source vetting records",
              "Bias remediation documentation"
            ]
          },
          {
            title: "Sec. 4.3 - Outcome Monitoring",
            description: "Monitor AI system outcomes for discriminatory patterns",
            order_no: 3,
            summary: "Continuously monitor AI system outcomes to detect disparate impact or differential treatment based on protected characteristics. Establish metrics and thresholds for identifying potential discrimination",
            questions: [
              "Is outcome monitoring implemented?",
              "Are metrics established for discrimination detection?",
              "Are monitoring thresholds defined?",
              "Is there process for responding to findings?"
            ],
            evidence_examples: [
              "Monitoring procedures",
              "Discrimination detection metrics",
              "Threshold documentation",
              "Response procedures"
            ]
          },
          {
            title: "Sec. 4.4 - Remediation Procedures",
            description: "Establish procedures for remediating discovered discrimination",
            order_no: 4,
            summary: "Implement procedures for addressing algorithmic discrimination when discovered, including root cause analysis, system correction, affected consumer notification, and prevention of recurrence",
            questions: [
              "Are remediation procedures established?",
              "Is root cause analysis conducted?",
              "Are affected consumers notified?",
              "Are preventive measures implemented?"
            ],
            evidence_examples: [
              "Remediation procedures",
              "Root cause analysis records",
              "Consumer notification records",
              "Prevention measure documentation"
            ]
          },
          {
            title: "Sec. 4.5 - Fair Lending and Insurance Considerations",
            description: "Address specific discrimination concerns in lending and insurance",
            order_no: 5,
            summary: "For AI used in lending and insurance decisions, implement additional safeguards to prevent discrimination. Consider intersection with federal fair lending and insurance regulations",
            questions: [
              "Are additional safeguards in place for lending/insurance AI?",
              "Is there compliance with fair lending laws?",
              "Are insurance-specific regulations addressed?",
              "Is disparate impact analyzed for these domains?"
            ],
            evidence_examples: [
              "Lending AI safeguards",
              "Fair lending compliance documentation",
              "Insurance regulation compliance",
              "Domain-specific impact analysis"
            ]
          }
        ]
      },
      {
        title: "Chapter 5: Consumer Rights and Protections",
        description: "Consumer rights under the Colorado AI Act and protection mechanisms",
        order_no: 5,
        items: [
          {
            title: "Sec. 5.1 - Right to Disclosure",
            description: "Consumers' right to know when AI is used in decisions",
            order_no: 1,
            summary: "Consumers have the right to be informed when a high-risk AI system is used to make or substantially contribute to consequential decisions about them",
            questions: [
              "Can all AI-influenced decisions be identified?",
              "Is disclosure provided consistently?",
              "Is disclosure clear and understandable?",
              "Are disclosure records maintained?"
            ],
            evidence_examples: [
              "Disclosure procedures",
              "Disclosure templates",
              "Consistency verification",
              "Disclosure records"
            ]
          },
          {
            title: "Sec. 5.2 - Right to Explanation",
            description: "Consumers' right to explanation of adverse decisions",
            order_no: 2,
            summary: "For adverse decisions, consumers have the right to receive a meaningful explanation including principal factors, data used, and the AI system's role in the decision",
            questions: [
              "Can meaningful explanations be provided?",
              "Are explanations in plain language?",
              "Do explanations cover required elements?",
              "Are explanations provided timely?"
            ],
            evidence_examples: [
              "Explanation capability",
              "Plain language guidelines",
              "Explanation completeness verification",
              "Response time tracking"
            ]
          },
          {
            title: "Sec. 5.3 - Right to Appeal",
            description: "Consumers' right to appeal AI-influenced decisions",
            order_no: 3,
            summary: "Consumers have the right to appeal adverse decisions made or influenced by AI, including the right to human review of the decision",
            questions: [
              "Is appeal process established?",
              "Can consumers access human review?",
              "Are appeals resolved timely?",
              "Are appeal outcomes documented?"
            ],
            evidence_examples: [
              "Appeal procedures",
              "Human review process",
              "Appeal timeline standards",
              "Appeal outcome records"
            ]
          },
          {
            title: "Sec. 5.4 - Right to Data Correction",
            description: "Consumers' right to correct inaccurate data",
            order_no: 4,
            summary: "Consumers have the right to correct inaccurate personal data that was used in AI-influenced decisions. Organizations must have procedures for receiving and processing correction requests",
            questions: [
              "Is data correction process established?",
              "Can corrections be processed efficiently?",
              "Are decisions re-evaluated after corrections?",
              "Are correction records maintained?"
            ],
            evidence_examples: [
              "Data correction procedures",
              "Correction request handling",
              "Re-evaluation procedures",
              "Correction records"
            ]
          },
          {
            title: "Sec. 5.5 - Non-Retaliation Protection",
            description: "Protection against retaliation for exercising rights",
            order_no: 5,
            summary: "Consumers must not face retaliation for exercising their rights under the Act, including filing complaints, requesting information, or appealing decisions",
            questions: [
              "Is non-retaliation policy in place?",
              "Are staff trained on non-retaliation?",
              "Is there monitoring for potential retaliation?",
              "Are retaliation complaints investigated?"
            ],
            evidence_examples: [
              "Non-retaliation policy",
              "Staff training records",
              "Monitoring procedures",
              "Complaint investigation records"
            ]
          }
        ]
      },
      {
        title: "Chapter 6: Impact Assessments",
        description: "Detailed requirements for algorithmic impact assessments",
        order_no: 6,
        items: [
          {
            title: "Sec. 6.1 - Assessment Methodology",
            description: "Establish methodology for conducting impact assessments",
            order_no: 1,
            summary: "Develop standardized methodology for impact assessments covering scope, analysis approach, stakeholder input, and documentation requirements",
            questions: [
              "Is assessment methodology documented?",
              "Is methodology appropriate for AI risks?",
              "Are stakeholder inputs incorporated?",
              "Is methodology consistently applied?"
            ],
            evidence_examples: [
              "Assessment methodology document",
              "Stakeholder input procedures",
              "Methodology application records",
              "Consistency verification"
            ]
          },
          {
            title: "Sec. 6.2 - Purpose and Use Case Analysis",
            description: "Document AI system purpose and intended use cases",
            order_no: 2,
            summary: "Assessments must include clear documentation of the AI system's purpose, intended use cases, and the decisions it will inform or make",
            questions: [
              "Is system purpose clearly documented?",
              "Are intended use cases specified?",
              "Are decision types identified?",
              "Are boundaries of use defined?"
            ],
            evidence_examples: [
              "Purpose documentation",
              "Use case specifications",
              "Decision type inventory",
              "Use boundary documentation"
            ]
          },
          {
            title: "Sec. 6.3 - Discrimination Risk Analysis",
            description: "Analyze risks of algorithmic discrimination",
            order_no: 3,
            summary: "Assessments must evaluate potential for algorithmic discrimination based on all protected characteristics, considering both direct discrimination and proxy variables",
            questions: [
              "Are discrimination risks thoroughly analyzed?",
              "Are all protected characteristics considered?",
              "Are proxy variables identified?",
              "Is analysis methodology sound?"
            ],
            evidence_examples: [
              "Discrimination risk analysis",
              "Protected characteristic coverage",
              "Proxy variable identification",
              "Analysis methodology documentation"
            ]
          },
          {
            title: "Sec. 6.4 - Mitigation Measures",
            description: "Document measures to mitigate identified risks",
            order_no: 4,
            summary: "Assessments must document specific measures implemented to mitigate identified discrimination risks, including technical, procedural, and governance measures",
            questions: [
              "Are mitigation measures documented?",
              "Do measures address identified risks?",
              "Are measures implemented and tested?",
              "Is effectiveness evaluated?"
            ],
            evidence_examples: [
              "Mitigation measure documentation",
              "Risk-mitigation mapping",
              "Implementation verification",
              "Effectiveness evaluation"
            ]
          },
          {
            title: "Sec. 6.5 - Assessment Retention and Updates",
            description: "Retain assessments and update annually or upon changes",
            order_no: 5,
            summary: "Impact assessments must be retained for at least three years after the AI system is discontinued. Assessments must be updated annually and when significant changes occur",
            questions: [
              "Are assessments properly retained?",
              "Is retention period at least 3 years post-discontinuation?",
              "Are annual updates conducted?",
              "Are changes triggering updates identified?"
            ],
            evidence_examples: [
              "Retention policy compliance",
              "Assessment archive",
              "Annual update schedule",
              "Change trigger procedures"
            ]
          }
        ]
      },
      {
        title: "Chapter 7: Data Governance",
        description: "Requirements for managing data used in high-risk AI systems",
        order_no: 7,
        items: [
          {
            title: "Sec. 7.1 - Data Quality Standards",
            description: "Establish and maintain data quality standards",
            order_no: 1,
            summary: "Implement data quality standards for AI training and operational data including accuracy, completeness, timeliness, and relevance requirements",
            questions: [
              "Are data quality standards documented?",
              "Is data accuracy measured?",
              "Is data completeness assessed?",
              "Are quality issues addressed?"
            ],
            evidence_examples: [
              "Data quality standards",
              "Quality measurement results",
              "Completeness assessments",
              "Quality improvement records"
            ]
          },
          {
            title: "Sec. 7.2 - Data Lineage and Documentation",
            description: "Document data sources, transformations, and lineage",
            order_no: 2,
            summary: "Maintain documentation of data sources, collection methods, transformations applied, and data lineage to enable understanding and audit of data used in AI decisions",
            questions: [
              "Is data lineage documented?",
              "Are data sources traceable?",
              "Are transformations documented?",
              "Can data be audited?"
            ],
            evidence_examples: [
              "Data lineage documentation",
              "Source traceability records",
              "Transformation documentation",
              "Audit capability demonstration"
            ]
          },
          {
            title: "Sec. 7.3 - Protected Characteristic Data",
            description: "Appropriately handle data related to protected characteristics",
            order_no: 3,
            summary: "Implement appropriate safeguards for data related to protected characteristics. Such data may be necessary for bias testing but requires enhanced protections and use limitations",
            questions: [
              "Is protected characteristic data identified?",
              "Are enhanced safeguards implemented?",
              "Is use limited to legitimate purposes?",
              "Is access appropriately restricted?"
            ],
            evidence_examples: [
              "Protected data inventory",
              "Enhanced safeguard documentation",
              "Use limitation policies",
              "Access control records"
            ]
          },
          {
            title: "Sec. 7.4 - Consumer Data Rights",
            description: "Honor consumer data rights under applicable laws",
            order_no: 4,
            summary: "Ensure AI data practices comply with Colorado Privacy Act and other applicable data protection laws, including consumer rights to access, delete, and correct data",
            questions: [
              "Are consumer data rights honored?",
              "Is there compliance with Colorado Privacy Act?",
              "Can access/deletion/correction requests be fulfilled?",
              "Are data practices documented?"
            ],
            evidence_examples: [
              "Data rights procedures",
              "Privacy Act compliance documentation",
              "Request fulfillment records",
              "Practice documentation"
            ]
          }
        ]
      },
      {
        title: "Chapter 8: Governance and Accountability",
        description: "Organizational governance structures for AI Act compliance",
        order_no: 8,
        items: [
          {
            title: "Sec. 8.1 - AI Governance Structure",
            description: "Establish governance structure for AI compliance",
            order_no: 1,
            summary: "Implement governance structure with clear roles, responsibilities, and accountability for Colorado AI Act compliance at executive and operational levels",
            questions: [
              "Is governance structure documented?",
              "Are roles and responsibilities clear?",
              "Is there executive accountability?",
              "Is operational responsibility assigned?"
            ],
            evidence_examples: [
              "Governance structure documentation",
              "Roles and responsibilities matrix",
              "Executive accountability documentation",
              "Operational responsibility assignments"
            ]
          },
          {
            title: "Sec. 8.2 - Compliance Program",
            description: "Implement AI Act compliance program",
            order_no: 2,
            summary: "Establish comprehensive compliance program including policies, procedures, training, monitoring, and reporting for Colorado AI Act requirements",
            questions: [
              "Is compliance program documented?",
              "Are policies and procedures complete?",
              "Is training provided to relevant personnel?",
              "Is compliance monitored and reported?"
            ],
            evidence_examples: [
              "Compliance program documentation",
              "Policies and procedures",
              "Training program and records",
              "Monitoring and reporting records"
            ]
          },
          {
            title: "Sec. 8.3 - Training and Awareness",
            description: "Train personnel on AI Act requirements and responsibilities",
            order_no: 3,
            summary: "Provide training to personnel involved in developing, deploying, or operating high-risk AI systems on their obligations under the Act and organizational procedures",
            questions: [
              "Is training program established?",
              "Does training cover Act requirements?",
              "Are relevant personnel trained?",
              "Is training documented and refreshed?"
            ],
            evidence_examples: [
              "Training program documentation",
              "Training content",
              "Training completion records",
              "Refresh schedule"
            ]
          },
          {
            title: "Sec. 8.4 - Internal Audit and Review",
            description: "Conduct internal audits of AI Act compliance",
            order_no: 4,
            summary: "Perform periodic internal audits to assess compliance with AI Act requirements. Track findings and implement corrective actions",
            questions: [
              "Are internal audits conducted?",
              "Do audits cover all requirements?",
              "Are findings tracked to resolution?",
              "Are audit results reported to leadership?"
            ],
            evidence_examples: [
              "Audit program documentation",
              "Audit reports",
              "Finding tracking records",
              "Leadership reporting"
            ]
          }
        ]
      },
      {
        title: "Chapter 9: Documentation and Records",
        description: "Documentation and record retention requirements",
        order_no: 9,
        items: [
          {
            title: "Sec. 9.1 - Technical Documentation",
            description: "Maintain technical documentation for high-risk AI systems",
            order_no: 1,
            summary: "Document AI system design, algorithms, training processes, validation methods, and performance characteristics sufficient to demonstrate compliance and enable audit",
            questions: [
              "Is technical documentation complete?",
              "Are algorithms documented?",
              "Is training process documented?",
              "Can compliance be demonstrated?"
            ],
            evidence_examples: [
              "Technical documentation package",
              "Algorithm documentation",
              "Training process documentation",
              "Compliance demonstration capability"
            ]
          },
          {
            title: "Sec. 9.2 - Decision Records",
            description: "Maintain records of AI-influenced decisions",
            order_no: 2,
            summary: "Keep records of consequential decisions made or influenced by high-risk AI, including inputs, outputs, and human review activities",
            questions: [
              "Are decision records maintained?",
              "Do records include inputs and outputs?",
              "Is human review documented?",
              "Can decisions be reconstructed?"
            ],
            evidence_examples: [
              "Decision logging system",
              "Input/output records",
              "Human review records",
              "Decision reconstruction capability"
            ]
          },
          {
            title: "Sec. 9.3 - Consumer Interaction Records",
            description: "Maintain records of consumer notifications and responses",
            order_no: 3,
            summary: "Document consumer notifications, explanation statements, appeals, and resolution outcomes related to AI-influenced decisions",
            questions: [
              "Are notification records maintained?",
              "Are explanations documented?",
              "Are appeals tracked to resolution?",
              "Can consumer interactions be retrieved?"
            ],
            evidence_examples: [
              "Notification records",
              "Explanation documentation",
              "Appeal tracking system",
              "Record retrieval capability"
            ]
          },
          {
            title: "Sec. 9.4 - Record Retention",
            description: "Retain records for required periods",
            order_no: 4,
            summary: "Retain impact assessments, decision records, and compliance documentation for at least three years after AI system discontinuation or decision date",
            questions: [
              "Is retention policy compliant?",
              "Are records securely stored?",
              "Can records be produced upon request?",
              "Is destruction properly managed?"
            ],
            evidence_examples: [
              "Retention policy",
              "Secure storage procedures",
              "Record production capability",
              "Destruction records"
            ]
          }
        ]
      },
      {
        title: "Chapter 10: Enforcement and Penalties",
        description: "Preparation for enforcement and penalty mitigation",
        order_no: 10,
        items: [
          {
            title: "Sec. 10.1 - Attorney General Authority",
            description: "Understand Attorney General enforcement authority",
            order_no: 1,
            summary: "The Colorado Attorney General has exclusive authority to enforce the AI Act, including investigation powers, civil penalties, and injunctive relief. Understand enforcement mechanisms and prepare accordingly",
            questions: [
              "Is AG enforcement authority understood?",
              "Is there process for responding to AG?",
              "Can documentation be produced promptly?",
              "Is there designated AG contact?"
            ],
            evidence_examples: [
              "Enforcement authority analysis",
              "AG response procedures",
              "Documentation production capability",
              "Designated contact information"
            ]
          },
          {
            title: "Sec. 10.2 - Affirmative Defense",
            description: "Establish basis for affirmative defense if needed",
            order_no: 2,
            summary: "The Act provides affirmative defense for deployers who maintain and follow a risk management program, complete impact assessments, and comply with consumer notification requirements. Document compliance to support defense",
            questions: [
              "Are affirmative defense elements documented?",
              "Is risk management program maintained?",
              "Are impact assessments complete?",
              "Is consumer notification compliant?"
            ],
            evidence_examples: [
              "Affirmative defense documentation",
              "Risk management compliance evidence",
              "Impact assessment completeness",
              "Notification compliance records"
            ]
          },
          {
            title: "Sec. 10.3 - Cure Period",
            description: "Understand and prepare for cure period opportunity",
            order_no: 3,
            summary: "Before enforcement action, deployers may have opportunity to cure violations. Understand cure requirements and maintain ability to implement rapid remediation",
            questions: [
              "Is cure period understood?",
              "Can violations be quickly identified?",
              "Can remediation be implemented rapidly?",
              "Is cure documentation prepared?"
            ],
            evidence_examples: [
              "Cure period analysis",
              "Violation identification capability",
              "Rapid remediation procedures",
              "Cure documentation templates"
            ]
          },
          {
            title: "Sec. 10.4 - Civil Penalty Mitigation",
            description: "Implement measures to mitigate potential civil penalties",
            order_no: 4,
            summary: "Civil penalties can reach $20,000 per violation. Mitigate penalty risk through documented compliance efforts, good faith implementation, and prompt violation remediation",
            questions: [
              "Is penalty structure understood?",
              "Are compliance efforts documented?",
              "Is good faith demonstrable?",
              "Are violations promptly remediated?"
            ],
            evidence_examples: [
              "Penalty risk assessment",
              "Compliance effort documentation",
              "Good faith evidence",
              "Remediation records"
            ]
          }
        ]
      }
    ]
  }
};

// plugins/colorado-ai-act/index.ts
var plugin = createFrameworkPlugin({
  key: "colorado-ai-act",
  name: "Colorado Artificial Intelligence Act",
  description: "Colorado AI Act compliance framework for preventing algorithmic discrimination in high-risk AI systems.",
  version: "1.0.0",
  author: "VerifyWise",
  template: template_default.framework,
  autoImport: true
});
var { metadata, install, uninstall, validateConfig, router } = plugin;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  install,
  metadata,
  router,
  uninstall,
  validateConfig
});
