/**
 * Bahrain Personal Data Protection Law Framework Plugin (Bundled)
 * Generated by build-framework-plugins.js
 */

"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// plugins/bahrain-pdpl/index.ts
var index_exports = {};
__export(index_exports, {
  install: () => install,
  metadata: () => metadata,
  router: () => router,
  uninstall: () => uninstall,
  validateConfig: () => validateConfig
});
module.exports = __toCommonJS(index_exports);

// packages/custom-framework-base/index.ts
async function ensureSharedTables(sequelize, tenantId) {
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_frameworks (
      id SERIAL PRIMARY KEY,
      plugin_key VARCHAR(100),
      name VARCHAR(255) NOT NULL,
      description TEXT,
      version VARCHAR(50) DEFAULT '1.0.0',
      is_organizational BOOLEAN DEFAULT FALSE,
      hierarchy_type VARCHAR(50) NOT NULL DEFAULT 'two_level',
      level_1_name VARCHAR(100) NOT NULL DEFAULT 'Category',
      level_2_name VARCHAR(100) NOT NULL DEFAULT 'Control',
      level_3_name VARCHAR(100),
      file_source VARCHAR(100),
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = '${tenantId}'
        AND table_name = 'custom_frameworks'
        AND column_name = 'plugin_key'
      ) THEN
        ALTER TABLE "${tenantId}".custom_frameworks ADD COLUMN plugin_key VARCHAR(100);
      END IF;
    END $$;
  `);
  await sequelize.query(`
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = '${tenantId}'
        AND table_name = 'custom_frameworks'
        AND column_name = 'file_source'
      ) THEN
        ALTER TABLE "${tenantId}".custom_frameworks ADD COLUMN file_source VARCHAR(100);
      END IF;
    END $$;
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level1 (
      id SERIAL PRIMARY KEY,
      framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_frameworks(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2 (
      id SERIAL PRIMARY KEY,
      level1_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level1(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      summary TEXT,
      questions TEXT[],
      evidence_examples TEXT[],
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3 (
      id SERIAL PRIMARY KEY,
      level2_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      summary TEXT,
      questions TEXT[],
      evidence_examples TEXT[],
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_projects (
      id SERIAL PRIMARY KEY,
      framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_frameworks(id) ON DELETE CASCADE,
      project_id INTEGER NOT NULL,
      created_at TIMESTAMP DEFAULT NOW(),
      UNIQUE(framework_id, project_id)
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2_impl (
      id SERIAL PRIMARY KEY,
      level2_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2(id) ON DELETE CASCADE,
      project_framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_projects(id) ON DELETE CASCADE,
      status VARCHAR(50) DEFAULT 'Not started',
      owner INTEGER,
      reviewer INTEGER,
      approver INTEGER,
      due_date DATE,
      implementation_details TEXT,
      evidence_links JSONB DEFAULT '[]',
      feedback_links JSONB DEFAULT '[]',
      auditor_feedback TEXT,
      is_demo BOOLEAN DEFAULT FALSE,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3_impl (
      id SERIAL PRIMARY KEY,
      level3_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level3(id) ON DELETE CASCADE,
      level2_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2_impl(id) ON DELETE CASCADE,
      status VARCHAR(50) DEFAULT 'Not started',
      owner INTEGER,
      reviewer INTEGER,
      approver INTEGER,
      due_date DATE,
      implementation_details TEXT,
      evidence_links JSONB DEFAULT '[]',
      feedback_links JSONB DEFAULT '[]',
      auditor_feedback TEXT,
      is_demo BOOLEAN DEFAULT FALSE,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2_risks (
      level2_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2_impl(id) ON DELETE CASCADE,
      risk_id INTEGER NOT NULL,
      PRIMARY KEY (level2_impl_id, risk_id)
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3_risks (
      level3_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level3_impl(id) ON DELETE CASCADE,
      risk_id INTEGER NOT NULL,
      PRIMARY KEY (level3_impl_id, risk_id)
    )
  `);
  const indexes = [
    `CREATE INDEX IF NOT EXISTS idx_cf_level1_framework ON "${tenantId}".custom_framework_level1(framework_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_level2_level1 ON "${tenantId}".custom_framework_level2(level1_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_level3_level2 ON "${tenantId}".custom_framework_level3(level2_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_l2impl_pf ON "${tenantId}".custom_framework_level2_impl(project_framework_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_l3impl_l2impl ON "${tenantId}".custom_framework_level3_impl(level2_impl_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_plugin_key ON "${tenantId}".custom_frameworks(plugin_key)`
  ];
  for (const idx of indexes) {
    await sequelize.query(idx);
  }
}
function toPgArray(arr) {
  if (!arr || arr.length === 0) return "{}";
  const escaped = arr.map((item) => {
    const escapedItem = String(item).replace(/\\/g, "\\\\").replace(/"/g, '\\"');
    return `"${escapedItem}"`;
  });
  return `{${escaped.join(",")}}`;
}
function generateFileSourceName(frameworkName) {
  const cleanName = frameworkName.trim();
  return `${cleanName} evidence`;
}
async function addFileSourceEnum(sequelize, sourceName) {
  try {
    const [existing] = await sequelize.query(
      `
      SELECT 1 FROM pg_enum
      WHERE enumtypid = (SELECT oid FROM pg_type WHERE typname = 'enum_files_source')
      AND enumlabel = :sourceName
    `,
      { replacements: { sourceName } }
    );
    if (existing.length === 0) {
      await sequelize.query(
        `ALTER TYPE public.enum_files_source ADD VALUE '${sourceName.replace(/'/g, "''")}'`
      );
      console.log(`[CustomFrameworkBase] Added file source enum: "${sourceName}"`);
    }
    return true;
  } catch (error) {
    console.error(`[CustomFrameworkBase] Failed to add file source enum: ${error.message}`);
    return false;
  }
}
async function importFramework(frameworkData, tenantId, sequelize, pluginKey) {
  const fileSource = generateFileSourceName(frameworkData.name);
  await addFileSourceEnum(sequelize, fileSource);
  const transaction = await sequelize.transaction();
  try {
    const [frameworkResult] = await sequelize.query(
      `INSERT INTO "${tenantId}".custom_frameworks
       (plugin_key, name, description, version, is_organizational, hierarchy_type, level_1_name, level_2_name, level_3_name, file_source, created_at)
       VALUES (:plugin_key, :name, :description, :version, :is_organizational, :hierarchy_type, :level_1_name, :level_2_name, :level_3_name, :file_source, NOW())
       RETURNING id`,
      {
        replacements: {
          plugin_key: pluginKey,
          name: frameworkData.name,
          description: frameworkData.description,
          version: frameworkData.version || "1.0.0",
          is_organizational: frameworkData.is_organizational,
          hierarchy_type: frameworkData.hierarchy.type,
          level_1_name: frameworkData.hierarchy.level1_name,
          level_2_name: frameworkData.hierarchy.level2_name,
          level_3_name: frameworkData.hierarchy.level3_name || null,
          file_source: fileSource
        },
        transaction
      }
    );
    const frameworkId = frameworkResult[0].id;
    let itemsCreated = 0;
    for (const level1 of frameworkData.structure) {
      const [level1Result] = await sequelize.query(
        `INSERT INTO "${tenantId}".custom_framework_level1
         (framework_id, title, description, order_no, metadata)
         VALUES (:framework_id, :title, :description, :order_no, :metadata)
         RETURNING id`,
        {
          replacements: {
            framework_id: frameworkId,
            title: level1.title,
            description: level1.description || null,
            order_no: level1.order_no,
            metadata: JSON.stringify(level1.metadata || {})
          },
          transaction
        }
      );
      const level1Id = level1Result[0].id;
      itemsCreated++;
      for (const level2 of level1.items || []) {
        const [level2Result] = await sequelize.query(
          `INSERT INTO "${tenantId}".custom_framework_level2
           (level1_id, title, description, order_no, summary, questions, evidence_examples, metadata)
           VALUES (:level1_id, :title, :description, :order_no, :summary, :questions, :evidence_examples, :metadata)
           RETURNING id`,
          {
            replacements: {
              level1_id: level1Id,
              title: level2.title,
              description: level2.description || null,
              order_no: level2.order_no,
              summary: level2.summary || null,
              questions: toPgArray(level2.questions),
              evidence_examples: toPgArray(level2.evidence_examples),
              metadata: JSON.stringify(level2.metadata || {})
            },
            transaction
          }
        );
        const level2Id = level2Result[0].id;
        itemsCreated++;
        if (frameworkData.hierarchy.type === "three_level" && level2.items) {
          for (const level3 of level2.items) {
            await sequelize.query(
              `INSERT INTO "${tenantId}".custom_framework_level3
               (level2_id, title, description, order_no, summary, questions, evidence_examples, metadata)
               VALUES (:level2_id, :title, :description, :order_no, :summary, :questions, :evidence_examples, :metadata)`,
              {
                replacements: {
                  level2_id: level2Id,
                  title: level3.title,
                  description: level3.description || null,
                  order_no: level3.order_no,
                  summary: level3.summary || null,
                  questions: toPgArray(level3.questions),
                  evidence_examples: toPgArray(level3.evidence_examples),
                  metadata: JSON.stringify(level3.metadata || {})
                },
                transaction
              }
            );
            itemsCreated++;
          }
        }
      }
    }
    await transaction.commit();
    return { frameworkId, itemsCreated, fileSource };
  } catch (error) {
    await transaction.rollback();
    throw error;
  }
}
function createRouteHandlers(pluginKey, config) {
  async function handleGetFrameworks(ctx) {
    const { sequelize, tenantId, query } = ctx;
    const showAll = query.all === "true";
    try {
      const whereClause = showAll ? "1=1" : "cf.plugin_key = :pluginKey OR cf.plugin_key IS NULL";
      const [frameworks] = await sequelize.query(
        `
        SELECT
          cf.id,
          cf.plugin_key,
          cf.name,
          cf.description,
          cf.version,
          cf.is_organizational,
          cf.hierarchy_type,
          cf.level_1_name,
          cf.level_2_name,
          cf.level_3_name,
          cf.file_source,
          cf.created_at,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level1 WHERE framework_id = cf.id) as level1_count,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level2 l2
           JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
           WHERE l1.framework_id = cf.id) as level2_count,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level3 l3
           JOIN "${tenantId}".custom_framework_level2 l2 ON l3.level2_id = l2.id
           JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
           WHERE l1.framework_id = cf.id) as level3_count
        FROM "${tenantId}".custom_frameworks cf
        WHERE ${whereClause}
        ORDER BY cf.created_at DESC
      `,
        { replacements: { pluginKey } }
      );
      return { status: 200, data: frameworks };
    } catch (error) {
      return { status: 500, data: { message: `Failed to fetch frameworks: ${error.message}` } };
    }
  }
  async function handleGetFrameworkById(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [meta] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (meta.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const [level1Items] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_framework_level1
         WHERE framework_id = :frameworkId ORDER BY order_no`,
        { replacements: { frameworkId } }
      );
      for (const l1 of level1Items) {
        const [level2Items] = await sequelize.query(
          `SELECT * FROM "${tenantId}".custom_framework_level2
           WHERE level1_id = :level1Id ORDER BY order_no`,
          { replacements: { level1Id: l1.id } }
        );
        for (const l2 of level2Items) {
          if (meta[0].hierarchy_type === "three_level") {
            const [level3Items] = await sequelize.query(
              `SELECT * FROM "${tenantId}".custom_framework_level3
               WHERE level2_id = :level2Id ORDER BY order_no`,
              { replacements: { level2Id: l2.id } }
            );
            l2.items = level3Items;
          }
        }
        l1.items = level2Items;
      }
      const [linkedProjectsRaw] = await sequelize.query(
        `SELECT
          cfp.id as project_framework_id,
          cfp.project_id,
          cfp.created_at as added_at,
          p.project_title,
          COALESCE(p.is_organizational, false) as is_organizational
        FROM "${tenantId}".custom_framework_projects cfp
        JOIN "${tenantId}".projects p ON cfp.project_id = p.id
        WHERE cfp.framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      const linkedProjects = await Promise.all(
        linkedProjectsRaw.map(async (proj) => {
          let progressData;
          if (meta[0].hierarchy_type === "three_level") {
            [progressData] = await sequelize.query(
              `SELECT
                COUNT(*) as total,
                SUM(CASE WHEN l3.status = 'Implemented' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN l3.owner IS NOT NULL THEN 1 ELSE 0 END) as assigned
              FROM "${tenantId}".custom_framework_level3_impl l3
              JOIN "${tenantId}".custom_framework_level2_impl l2 ON l3.level2_impl_id = l2.id
              WHERE l2.project_framework_id = :projectFrameworkId`,
              { replacements: { projectFrameworkId: proj.project_framework_id } }
            );
          } else {
            [progressData] = await sequelize.query(
              `SELECT
                COUNT(*) as total,
                SUM(CASE WHEN status = 'Implemented' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN owner IS NOT NULL THEN 1 ELSE 0 END) as assigned
              FROM "${tenantId}".custom_framework_level2_impl
              WHERE project_framework_id = :projectFrameworkId`,
              { replacements: { projectFrameworkId: proj.project_framework_id } }
            );
          }
          const total = parseInt(progressData[0]?.total || "0");
          const completed = parseInt(progressData[0]?.completed || "0");
          const assigned = parseInt(progressData[0]?.assigned || "0");
          return {
            project_framework_id: proj.project_framework_id,
            project_id: proj.project_id,
            project_title: proj.project_title,
            is_organizational: proj.is_organizational,
            added_at: proj.added_at,
            progress: {
              total,
              completed,
              assigned,
              percentage: total > 0 ? Math.round(completed / total * 100) : 0
            }
          };
        })
      );
      return {
        status: 200,
        data: {
          ...meta[0],
          structure: level1Items,
          linkedProjects
        }
      };
    } catch (error) {
      return { status: 500, data: { message: `Failed to fetch structure: ${error.message}` } };
    }
  }
  async function handleDeleteFramework(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [framework] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (framework.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const [projects] = await sequelize.query(
        `SELECT COUNT(*) as count FROM "${tenantId}".custom_framework_projects WHERE framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (parseInt(projects[0].count) > 0) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_projects WHERE framework_id = :frameworkId`,
          { replacements: { frameworkId } }
        );
      }
      await sequelize.query(`DELETE FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`, {
        replacements: { frameworkId }
      });
      return { status: 200, data: { success: true, message: "Framework deleted" } };
    } catch (error) {
      return { status: 500, data: { message: `Delete failed: ${error.message}` } };
    }
  }
  async function handleAddToProject(ctx) {
    const { sequelize, tenantId, body } = ctx;
    const { frameworkId, projectId } = body;
    if (!frameworkId || !projectId) {
      return { status: 400, data: { message: "frameworkId and projectId are required" } };
    }
    try {
      const [framework] = await sequelize.query(
        `SELECT id, hierarchy_type FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (framework.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const hierarchyType = framework[0].hierarchy_type;
      const [existing] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_projects
         WHERE framework_id = :frameworkId AND project_id = :projectId`,
        { replacements: { frameworkId, projectId } }
      );
      if (existing.length > 0) {
        return { status: 400, data: { message: "Framework already added to this project" } };
      }
      const [insertResult] = await sequelize.query(
        `INSERT INTO "${tenantId}".custom_framework_projects (framework_id, project_id, created_at)
         VALUES (:frameworkId, :projectId, NOW())
         RETURNING id`,
        { replacements: { frameworkId, projectId } }
      );
      const projectFrameworkId = insertResult[0].id;
      const [level2Items] = await sequelize.query(
        `SELECT l2.id FROM "${tenantId}".custom_framework_level2 l2
         JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
         WHERE l1.framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      for (const l2 of level2Items) {
        const [implResult] = await sequelize.query(
          `INSERT INTO "${tenantId}".custom_framework_level2_impl
           (level2_id, project_framework_id, status, created_at, updated_at)
           VALUES (:level2_id, :project_framework_id, 'Not started', NOW(), NOW())
           RETURNING id`,
          { replacements: { level2_id: l2.id, project_framework_id: projectFrameworkId } }
        );
        if (hierarchyType === "three_level") {
          const [level3Items] = await sequelize.query(
            `SELECT id FROM "${tenantId}".custom_framework_level3 WHERE level2_id = :level2Id`,
            { replacements: { level2Id: l2.id } }
          );
          for (const l3 of level3Items) {
            await sequelize.query(
              `INSERT INTO "${tenantId}".custom_framework_level3_impl
               (level3_id, level2_impl_id, status, created_at, updated_at)
               VALUES (:level3_id, :level2_impl_id, 'Not started', NOW(), NOW())`,
              { replacements: { level3_id: l3.id, level2_impl_id: implResult[0].id } }
            );
          }
        }
      }
      return {
        status: 200,
        data: { success: true, message: "Framework added to project", projectFrameworkId }
      };
    } catch (error) {
      return { status: 500, data: { message: `Failed to add: ${error.message}` } };
    }
  }
  async function handleRemoveFromProject(ctx) {
    const { sequelize, tenantId, body } = ctx;
    const { frameworkId, projectId } = body;
    if (!frameworkId || !projectId) {
      return { status: 400, data: { message: "frameworkId and projectId are required" } };
    }
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".custom_framework_projects
         WHERE framework_id = :frameworkId AND project_id = :projectId`,
        { replacements: { frameworkId, projectId } }
      );
      return { status: 200, data: { success: true, message: "Framework removed from project" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to remove: ${error.message}` } };
    }
  }
  async function handleGetProjectFrameworks(ctx) {
    const { sequelize, tenantId, params, query } = ctx;
    const projectId = parseInt(params.projectId);
    const isOrganizational = query.is_organizational === "true";
    try {
      const [frameworks] = await sequelize.query(
        `
        SELECT cf.*, cf.id as framework_id, cfp.id as project_framework_id, cfp.created_at as added_at
        FROM "${tenantId}".custom_frameworks cf
        JOIN "${tenantId}".custom_framework_projects cfp ON cf.id = cfp.framework_id
        WHERE cfp.project_id = :projectId
        ORDER BY cf.name
      `,
        { replacements: { projectId } }
      );
      return { status: 200, data: frameworks };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleGetProjectFramework(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const projectId = parseInt(params.projectId);
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [projectFramework] = await sequelize.query(
        `SELECT cfp.id as project_framework_id, cf.*
         FROM "${tenantId}".custom_framework_projects cfp
         JOIN "${tenantId}".custom_frameworks cf ON cfp.framework_id = cf.id
         WHERE cfp.project_id = :projectId AND cfp.framework_id = :frameworkId`,
        { replacements: { projectId, frameworkId } }
      );
      if (projectFramework.length === 0) {
        return { status: 404, data: { message: "Framework not found in project" } };
      }
      const pf = projectFramework[0];
      const projectFrameworkId = pf.project_framework_id;
      const [level1Items] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_framework_level1
         WHERE framework_id = :frameworkId ORDER BY order_no`,
        { replacements: { frameworkId } }
      );
      for (const l1 of level1Items) {
        const [level2Items] = await sequelize.query(
          `SELECT l2.*,
                  impl.id as impl_id, impl.status, impl.owner, impl.reviewer, impl.approver,
                  impl.due_date, impl.implementation_details, impl.evidence_links,
                  impl.feedback_links, impl.auditor_feedback,
                  u_owner.name as owner_name, u_owner.surname as owner_surname,
                  u_reviewer.name as reviewer_name, u_reviewer.surname as reviewer_surname,
                  u_approver.name as approver_name, u_approver.surname as approver_surname
           FROM "${tenantId}".custom_framework_level2 l2
           LEFT JOIN "${tenantId}".custom_framework_level2_impl impl
             ON l2.id = impl.level2_id AND impl.project_framework_id = :projectFrameworkId
           LEFT JOIN public.users u_owner ON impl.owner = u_owner.id
           LEFT JOIN public.users u_reviewer ON impl.reviewer = u_reviewer.id
           LEFT JOIN public.users u_approver ON impl.approver = u_approver.id
           WHERE l2.level1_id = :level1Id
           ORDER BY l2.order_no`,
          { replacements: { level1Id: l1.id, projectFrameworkId } }
        );
        for (const l2 of level2Items) {
          if (l2.impl_id) {
            const [risks] = await sequelize.query(
              `SELECT r.id, r.risk_name, r.risk_description
               FROM "${tenantId}".custom_framework_level2_risks lr
               JOIN "${tenantId}".risks r ON lr.risk_id = r.id
               WHERE lr.level2_impl_id = :implId`,
              { replacements: { implId: l2.impl_id } }
            );
            l2.linked_risks = risks;
            const [linkedFiles] = await sequelize.query(
              `SELECT
                f.id,
                f.filename,
                f.size,
                f.type as mimetype,
                f.uploaded_time as upload_date,
                u.name as uploader_name,
                u.surname as uploader_surname,
                fel.link_type
              FROM "${tenantId}".file_entity_links fel
              JOIN "${tenantId}".files f ON fel.file_id = f.id
              LEFT JOIN public.users u ON f.uploaded_by = u.id
              WHERE fel.framework_type = :frameworkType
                AND fel.entity_type = 'level2_impl'
                AND fel.entity_id = :implId
              ORDER BY fel.created_at DESC`,
              { replacements: { frameworkType: pluginKey, implId: l2.impl_id } }
            );
            l2.linked_files = linkedFiles;
          } else {
            l2.linked_risks = [];
            l2.linked_files = [];
          }
          if (pf.hierarchy_type === "three_level") {
            const [level3Items] = await sequelize.query(
              `SELECT l3.*,
                      impl.id as impl_id, impl.status, impl.owner, impl.reviewer, impl.approver,
                      impl.due_date, impl.implementation_details, impl.evidence_links
               FROM "${tenantId}".custom_framework_level3 l3
               LEFT JOIN "${tenantId}".custom_framework_level3_impl impl
                 ON l3.id = impl.level3_id AND impl.level2_impl_id = :level2ImplId
               WHERE l3.level2_id = :level2Id
               ORDER BY l3.order_no`,
              { replacements: { level2Id: l2.id, level2ImplId: l2.impl_id } }
            );
            for (const l3 of level3Items) {
              if (l3.impl_id) {
                const [l3Files] = await sequelize.query(
                  `SELECT
                    f.id,
                    f.filename,
                    f.size,
                    f.type as mimetype,
                    f.uploaded_time as upload_date,
                    u.name as uploader_name,
                    u.surname as uploader_surname,
                    fel.link_type
                  FROM "${tenantId}".file_entity_links fel
                  JOIN "${tenantId}".files f ON fel.file_id = f.id
                  LEFT JOIN public.users u ON f.uploaded_by = u.id
                  WHERE fel.framework_type = :frameworkType
                    AND fel.entity_type = 'level3_impl'
                    AND fel.entity_id = :implId
                  ORDER BY fel.created_at DESC`,
                  { replacements: { frameworkType: pluginKey, implId: l3.impl_id } }
                );
                l3.linked_files = l3Files;
              } else {
                l3.linked_files = [];
              }
            }
            l2.items = level3Items;
          }
        }
        l1.items = level2Items;
      }
      return {
        status: 200,
        data: {
          projectFrameworkId,
          frameworkId: pf.id,
          name: pf.name,
          description: pf.description,
          is_organizational: pf.is_organizational,
          hierarchy_type: pf.hierarchy_type,
          level_1_name: pf.level_1_name,
          level_2_name: pf.level_2_name,
          level_3_name: pf.level_3_name,
          file_source: pf.file_source,
          structure: level1Items
        }
      };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleGetProgress(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const projectId = parseInt(params.projectId);
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [projectFramework] = await sequelize.query(
        `SELECT cfp.id as project_framework_id, cf.hierarchy_type
         FROM "${tenantId}".custom_framework_projects cfp
         JOIN "${tenantId}".custom_frameworks cf ON cfp.framework_id = cf.id
         WHERE cfp.project_id = :projectId AND cfp.framework_id = :frameworkId`,
        { replacements: { projectId, frameworkId } }
      );
      if (projectFramework.length === 0) {
        return { status: 404, data: { message: "Framework not found in project" } };
      }
      const projectFrameworkId = projectFramework[0].project_framework_id;
      const hierarchyType = projectFramework[0].hierarchy_type;
      const [level2Stats] = await sequelize.query(
        `SELECT
           COUNT(*) as total,
           COUNT(CASE WHEN status = 'Implemented' THEN 1 END) as completed,
           COUNT(CASE WHEN owner IS NOT NULL THEN 1 END) as assigned
         FROM "${tenantId}".custom_framework_level2_impl
         WHERE project_framework_id = :projectFrameworkId`,
        { replacements: { projectFrameworkId } }
      );
      const result = {
        level2: {
          total: parseInt(level2Stats[0].total),
          completed: parseInt(level2Stats[0].completed),
          assigned: parseInt(level2Stats[0].assigned),
          percentage: parseInt(level2Stats[0].total) > 0 ? Math.round(
            parseInt(level2Stats[0].completed) / parseInt(level2Stats[0].total) * 100
          ) : 0
        }
      };
      if (hierarchyType === "three_level") {
        const [level3Stats] = await sequelize.query(
          `SELECT
             COUNT(*) as total,
             COUNT(CASE WHEN l3.status = 'Implemented' THEN 1 END) as completed,
             COUNT(CASE WHEN l3.owner IS NOT NULL THEN 1 END) as assigned
           FROM "${tenantId}".custom_framework_level3_impl l3
           JOIN "${tenantId}".custom_framework_level2_impl l2 ON l3.level2_impl_id = l2.id
           WHERE l2.project_framework_id = :projectFrameworkId`,
          { replacements: { projectFrameworkId } }
        );
        result.level3 = {
          total: parseInt(level3Stats[0].total),
          completed: parseInt(level3Stats[0].completed),
          assigned: parseInt(level3Stats[0].assigned),
          percentage: parseInt(level3Stats[0].total) > 0 ? Math.round(
            parseInt(level3Stats[0].completed) / parseInt(level3Stats[0].total) * 100
          ) : 0
        };
        result.overall = result.level3;
      } else {
        result.overall = result.level2;
      }
      return { status: 200, data: result };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleUpdateLevel2(ctx) {
    const { sequelize, tenantId, params, body } = ctx;
    const implId = parseInt(params.level2Id);
    try {
      const updateFields = [];
      const replacements = { id: implId };
      const allowedFields = [
        "status",
        "owner",
        "reviewer",
        "approver",
        "due_date",
        "implementation_details",
        "evidence_links",
        "feedback_links",
        "auditor_feedback"
      ];
      for (const field of allowedFields) {
        if (body[field] !== void 0) {
          if (field === "evidence_links" || field === "feedback_links") {
            updateFields.push(`${field} = :${field}::jsonb`);
            replacements[field] = JSON.stringify(body[field]);
          } else if (field === "due_date" && body[field] === null) {
            updateFields.push(`${field} = NULL`);
          } else {
            updateFields.push(`${field} = :${field}`);
            replacements[field] = body[field];
          }
        }
      }
      if (updateFields.length === 0) {
        return { status: 400, data: { message: "No fields to update" } };
      }
      updateFields.push("updated_at = NOW()");
      await sequelize.query(
        `UPDATE "${tenantId}".custom_framework_level2_impl
         SET ${updateFields.join(", ")}
         WHERE id = :id`,
        { replacements }
      );
      if (body.risks_to_add && Array.isArray(body.risks_to_add)) {
        for (const riskId of body.risks_to_add) {
          await sequelize.query(
            `INSERT INTO "${tenantId}".custom_framework_level2_risks (level2_impl_id, risk_id)
             VALUES (:implId, :riskId)
             ON CONFLICT DO NOTHING`,
            { replacements: { implId, riskId } }
          );
        }
      }
      if (body.risks_to_remove && Array.isArray(body.risks_to_remove)) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_level2_risks
           WHERE level2_impl_id = :implId AND risk_id = ANY(:risks)`,
          { replacements: { implId, risks: body.risks_to_remove } }
        );
      }
      return { status: 200, data: { success: true, message: "Updated successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Update failed: ${error.message}` } };
    }
  }
  async function handleUpdateLevel3(ctx) {
    const { sequelize, tenantId, params, body } = ctx;
    const implId = parseInt(params.level3Id);
    try {
      const updateFields = [];
      const replacements = { id: implId };
      const allowedFields = [
        "status",
        "owner",
        "reviewer",
        "approver",
        "due_date",
        "implementation_details",
        "evidence_links",
        "feedback_links",
        "auditor_feedback"
      ];
      for (const field of allowedFields) {
        if (body[field] !== void 0) {
          if (field === "evidence_links" || field === "feedback_links") {
            updateFields.push(`${field} = :${field}::jsonb`);
            replacements[field] = JSON.stringify(body[field]);
          } else if (field === "due_date" && body[field] === null) {
            updateFields.push(`${field} = NULL`);
          } else {
            updateFields.push(`${field} = :${field}`);
            replacements[field] = body[field];
          }
        }
      }
      if (updateFields.length === 0) {
        return { status: 400, data: { message: "No fields to update" } };
      }
      updateFields.push("updated_at = NOW()");
      await sequelize.query(
        `UPDATE "${tenantId}".custom_framework_level3_impl
         SET ${updateFields.join(", ")}
         WHERE id = :id`,
        { replacements }
      );
      return { status: 200, data: { success: true, message: "Updated successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Update failed: ${error.message}` } };
    }
  }
  async function handleAttachFilesToLevel2(ctx) {
    const { sequelize, tenantId, userId, params, body } = ctx;
    const implId = parseInt(params.level2Id);
    const { file_ids, link_type = "evidence" } = body;
    if (!file_ids || !Array.isArray(file_ids) || file_ids.length === 0) {
      return { status: 400, data: { message: "file_ids array is required" } };
    }
    try {
      const [impl] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_level2_impl WHERE id = :implId`,
        { replacements: { implId } }
      );
      if (impl.length === 0) {
        return { status: 404, data: { message: "Implementation record not found" } };
      }
      const results = [];
      for (const fileId of file_ids) {
        try {
          await sequelize.query(
            `INSERT INTO "${tenantId}".file_entity_links
             (file_id, framework_type, entity_type, entity_id, link_type, created_by, created_at)
             VALUES (:fileId, :frameworkType, 'level2_impl', :entityId, :linkType, :userId, NOW())
             ON CONFLICT (file_id, framework_type, entity_type, entity_id) DO NOTHING`,
            {
              replacements: {
                fileId,
                frameworkType: pluginKey,
                entityId: implId,
                linkType: link_type,
                userId
              }
            }
          );
          results.push({ file_id: fileId, success: true, message: "Attached" });
        } catch (err) {
          results.push({ file_id: fileId, success: false, message: err.message });
        }
      }
      return { status: 200, data: { message: "Files attached", results } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to attach files: ${error.message}` } };
    }
  }
  async function handleGetLevel2Files(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level2Id);
    try {
      const [files] = await sequelize.query(
        `SELECT
          f.id,
          f.filename,
          f.size,
          f.type as mimetype,
          f.uploaded_time as upload_date,
          f.uploaded_by,
          u.name as uploader_name,
          u.surname as uploader_surname,
          fel.link_type,
          fel.created_at as linked_at
        FROM "${tenantId}".file_entity_links fel
        JOIN "${tenantId}".files f ON fel.file_id = f.id
        LEFT JOIN public.users u ON f.uploaded_by = u.id
        WHERE fel.framework_type = :frameworkType
          AND fel.entity_type = 'level2_impl'
          AND fel.entity_id = :entityId
        ORDER BY fel.created_at DESC`,
        {
          replacements: {
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: files };
    } catch (error) {
      return { status: 500, data: { message: `Failed to get files: ${error.message}` } };
    }
  }
  async function handleDetachFileFromLevel2(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level2Id);
    const fileId = parseInt(params.fileId);
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".file_entity_links
         WHERE file_id = :fileId
           AND framework_type = :frameworkType
           AND entity_type = 'level2_impl'
           AND entity_id = :entityId`,
        {
          replacements: {
            fileId,
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: { message: "File detached successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to detach file: ${error.message}` } };
    }
  }
  async function handleAttachFilesToLevel3(ctx) {
    const { sequelize, tenantId, userId, params, body } = ctx;
    const implId = parseInt(params.level3Id);
    const { file_ids, link_type = "evidence" } = body;
    if (!file_ids || !Array.isArray(file_ids) || file_ids.length === 0) {
      return { status: 400, data: { message: "file_ids array is required" } };
    }
    try {
      const [impl] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_level3_impl WHERE id = :implId`,
        { replacements: { implId } }
      );
      if (impl.length === 0) {
        return { status: 404, data: { message: "Implementation record not found" } };
      }
      const results = [];
      for (const fileId of file_ids) {
        try {
          await sequelize.query(
            `INSERT INTO "${tenantId}".file_entity_links
             (file_id, framework_type, entity_type, entity_id, link_type, created_by, created_at)
             VALUES (:fileId, :frameworkType, 'level3_impl', :entityId, :linkType, :userId, NOW())
             ON CONFLICT (file_id, framework_type, entity_type, entity_id) DO NOTHING`,
            {
              replacements: {
                fileId,
                frameworkType: pluginKey,
                entityId: implId,
                linkType: link_type,
                userId
              }
            }
          );
          results.push({ file_id: fileId, success: true, message: "Attached" });
        } catch (err) {
          results.push({ file_id: fileId, success: false, message: err.message });
        }
      }
      return { status: 200, data: { message: "Files attached", results } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to attach files: ${error.message}` } };
    }
  }
  async function handleGetLevel3Files(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level3Id);
    try {
      const [files] = await sequelize.query(
        `SELECT
          f.id,
          f.filename,
          f.size,
          f.type as mimetype,
          f.uploaded_time as upload_date,
          f.uploaded_by,
          u.name as uploader_name,
          u.surname as uploader_surname,
          fel.link_type,
          fel.created_at as linked_at
        FROM "${tenantId}".file_entity_links fel
        JOIN "${tenantId}".files f ON fel.file_id = f.id
        LEFT JOIN public.users u ON f.uploaded_by = u.id
        WHERE fel.framework_type = :frameworkType
          AND fel.entity_type = 'level3_impl'
          AND fel.entity_id = :entityId
        ORDER BY fel.created_at DESC`,
        {
          replacements: {
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: files };
    } catch (error) {
      return { status: 500, data: { message: `Failed to get files: ${error.message}` } };
    }
  }
  async function handleDetachFileFromLevel3(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level3Id);
    const fileId = parseInt(params.fileId);
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".file_entity_links
         WHERE file_id = :fileId
           AND framework_type = :frameworkType
           AND entity_type = 'level3_impl'
           AND entity_id = :entityId`,
        {
          replacements: {
            fileId,
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: { message: "File detached successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to detach file: ${error.message}` } };
    }
  }
  return {
    handleGetFrameworks,
    handleGetFrameworkById,
    handleDeleteFramework,
    handleAddToProject,
    handleRemoveFromProject,
    handleGetProjectFrameworks,
    handleGetProjectFramework,
    handleGetProgress,
    handleUpdateLevel2,
    handleUpdateLevel3,
    // File attachment handlers
    handleAttachFilesToLevel2,
    handleGetLevel2Files,
    handleDetachFileFromLevel2,
    handleAttachFilesToLevel3,
    handleGetLevel3Files,
    handleDetachFileFromLevel3
  };
}
function createFrameworkPlugin(config) {
  const pluginKey = config.key;
  const metadata2 = {
    name: config.name,
    version: config.version || "1.0.0",
    author: config.author || "VerifyWise",
    description: config.description
  };
  async function install2(_userId, tenantId, _config, context) {
    const { sequelize } = context;
    try {
      await ensureSharedTables(sequelize, tenantId);
      if (config.autoImport !== false && config.template) {
        const [existing] = await sequelize.query(
          `SELECT id FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
          { replacements: { pluginKey } }
        );
        if (existing.length === 0) {
          const result = await importFramework(config.template, tenantId, sequelize, pluginKey);
          console.log(
            `[${config.name}] Auto-imported framework with ${result.itemsCreated} items`
          );
        }
      }
      return {
        success: true,
        message: `${config.name} plugin installed successfully.`,
        installedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
    } catch (error) {
      throw new Error(`Installation failed: ${error.message}`);
    }
  }
  async function uninstall2(_userId, tenantId, context) {
    const { sequelize } = context;
    try {
      const [frameworks] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
        { replacements: { pluginKey } }
      );
      const frameworkIds = frameworks.map((f) => f.id);
      if (frameworkIds.length > 0) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_projects WHERE framework_id IN (:ids)`,
          { replacements: { ids: frameworkIds } }
        );
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
          { replacements: { pluginKey } }
        );
      }
      return {
        success: true,
        message: `${config.name} plugin uninstalled successfully.`,
        uninstalledAt: (/* @__PURE__ */ new Date()).toISOString()
      };
    } catch (error) {
      throw new Error(`Uninstall failed: ${error.message}`);
    }
  }
  function validateConfig2(_config) {
    return { valid: true, errors: [] };
  }
  const handlers = createRouteHandlers(pluginKey, config);
  const router2 = {
    "GET /frameworks": handlers.handleGetFrameworks,
    "GET /frameworks/:frameworkId": handlers.handleGetFrameworkById,
    "DELETE /frameworks/:frameworkId": handlers.handleDeleteFramework,
    "POST /add-to-project": handlers.handleAddToProject,
    "POST /remove-from-project": handlers.handleRemoveFromProject,
    "GET /projects/:projectId/custom-frameworks": handlers.handleGetProjectFrameworks,
    "GET /projects/:projectId/frameworks/:frameworkId": handlers.handleGetProjectFramework,
    "GET /projects/:projectId/frameworks/:frameworkId/progress": handlers.handleGetProgress,
    "PATCH /level2/:level2Id": handlers.handleUpdateLevel2,
    "PATCH /level3/:level3Id": handlers.handleUpdateLevel3,
    // File attachment routes for level2 implementations
    "POST /level2/:level2Id/files": handlers.handleAttachFilesToLevel2,
    "GET /level2/:level2Id/files": handlers.handleGetLevel2Files,
    "DELETE /level2/:level2Id/files/:fileId": handlers.handleDetachFileFromLevel2,
    // File attachment routes for level3 implementations
    "POST /level3/:level3Id/files": handlers.handleAttachFilesToLevel3,
    "GET /level3/:level3Id/files": handlers.handleGetLevel3Files,
    "DELETE /level3/:level3Id/files/:fileId": handlers.handleDetachFileFromLevel3
  };
  return {
    metadata: metadata2,
    install: install2,
    uninstall: uninstall2,
    validateConfig: validateConfig2,
    router: router2
  };
}

// plugins/bahrain-pdpl/template.json
var template_default = {
  id: "bahrain-pdpl",
  name: "Bahrain Personal Data Protection Law",
  description: "Bahrain PDPL 30/2018, CBB AI Notice, and EDB AI Ethics Pledge compliance framework.",
  category: "Privacy",
  tags: ["Bahrain", "PDPL", "Privacy", "Data Protection", "Gulf", "AI Ethics", "CBB", "EDB"],
  framework: {
    name: "Bahrain Personal Data Protection Law",
    description: "Framework for compliance with Bahrain PDPL 30/2018, Central Bank of Bahrain AI Notice (2023), and EDB AI Ethics Pledge",
    version: "1.0.0",
    is_organizational: true,
    hierarchy: {
      type: "two_level",
      level1_name: "Chapter",
      level2_name: "Article"
    },
    structure: [
      {
        title: "Chapter 1: General Provisions",
        description: "Definitions, scope, and applicability of Bahrain PDPL 30/2018",
        order_no: 1,
        items: [
          {
            title: "Article 1 - Definitions",
            description: "Key definitions including personal data, sensitive data, data controller, data processor, and consent under Bahrain PDPL",
            order_no: 1,
            summary: "Establish definitions for Bahrain data protection terms",
            questions: [
              "Are all personal data types identified per Bahrain PDPL?",
              "Is sensitive data clearly categorized?",
              "Are data controller/processor roles defined?"
            ],
            evidence_examples: [
              "Data classification policy aligned with Bahrain PDPL",
              "Roles and responsibilities matrix",
              "Data inventory documentation"
            ]
          },
          {
            title: "Article 2 - Territorial Scope",
            description: "Law applies to processing within Bahrain and to Bahraini residents' data",
            order_no: 2,
            summary: "Define territorial and extraterritorial application",
            questions: [
              "Is data processing within Bahrain documented?",
              "Are extraterritorial processing activities identified?",
              "Are exemptions properly applied?"
            ],
            evidence_examples: [
              "Data processing inventory",
              "Territorial scope assessment",
              "Exemption justification records"
            ]
          },
          {
            title: "Article 3 - Personal Data Protection Authority",
            description: "The Ministry of Interior oversees data protection compliance",
            order_no: 3,
            summary: "Understand regulatory oversight structure",
            questions: [
              "Is relationship with Authority established?",
              "Are reporting requirements understood?",
              "Is registration completed where required?"
            ],
            evidence_examples: [
              "Authority registration",
              "Reporting schedule",
              "Communication records"
            ]
          }
        ]
      },
      {
        title: "Chapter 2: Data Processing Principles",
        description: "Core principles governing personal data processing under Bahrain PDPL",
        order_no: 2,
        items: [
          {
            title: "Article 4 - Lawfulness of Processing",
            description: "Personal data must be processed based on lawful grounds including consent",
            order_no: 1,
            summary: "Ensure lawful basis for all processing",
            questions: [
              "Is lawful basis documented for each processing activity?",
              "Is consent obtained where required?",
              "Are other lawful bases properly justified?"
            ],
            evidence_examples: [
              "Lawful basis register",
              "Consent records",
              "Processing justification documents"
            ]
          },
          {
            title: "Article 5 - Purpose Limitation",
            description: "Data must be collected for specified, explicit, and legitimate purposes",
            order_no: 2,
            summary: "Limit processing to specified purposes",
            questions: [
              "Are purposes clearly defined and documented?",
              "Is further processing compatible with original purpose?",
              "Are purpose changes communicated to data subjects?"
            ],
            evidence_examples: [
              "Purpose specification documents",
              "Compatibility assessments",
              "Data subject notifications"
            ]
          },
          {
            title: "Article 6 - Data Minimization",
            description: "Only collect data adequate, relevant, and necessary for the purpose",
            order_no: 3,
            summary: "Minimize data collection",
            questions: [
              "Is data collection limited to necessity?",
              "Are unnecessary data fields removed?",
              "Is periodic review conducted?"
            ],
            evidence_examples: [
              "Data minimization assessment",
              "Data field review records",
              "Collection justification"
            ]
          },
          {
            title: "Article 7 - Accuracy",
            description: "Personal data must be accurate and kept up to date",
            order_no: 4,
            summary: "Maintain data accuracy",
            questions: [
              "Are accuracy procedures in place?",
              "Can data subjects update their data?",
              "Is inaccurate data corrected promptly?"
            ],
            evidence_examples: [
              "Data quality procedures",
              "Update mechanisms",
              "Correction logs"
            ]
          },
          {
            title: "Article 8 - Storage Limitation",
            description: "Data must not be kept longer than necessary for the purpose",
            order_no: 5,
            summary: "Implement retention limits",
            questions: [
              "Are retention periods defined?",
              "Is data deleted when no longer needed?",
              "Are retention schedules enforced?"
            ],
            evidence_examples: [
              "Retention policy",
              "Deletion logs",
              "Retention schedule"
            ]
          },
          {
            title: "Article 9 - Security Measures",
            description: "Appropriate technical and organizational security measures required",
            order_no: 6,
            summary: "Implement security safeguards",
            questions: [
              "Are technical security measures implemented?",
              "Are organizational measures in place?",
              "Is access appropriately controlled?"
            ],
            evidence_examples: [
              "Security policy",
              "Technical controls documentation",
              "Access control matrix"
            ]
          }
        ]
      },
      {
        title: "Chapter 3: Data Subject Rights",
        description: "Rights granted to individuals under Bahrain PDPL",
        order_no: 3,
        items: [
          {
            title: "Article 10 - Right to Information",
            description: "Data subjects must be informed about processing of their data",
            order_no: 1,
            summary: "Provide transparent information",
            questions: [
              "Are privacy notices provided in Arabic and English?",
              "Is information clear and accessible?",
              "Are all required disclosures made?"
            ],
            evidence_examples: [
              "Privacy notices (Arabic/English)",
              "Information provision procedures",
              "Disclosure checklists"
            ]
          },
          {
            title: "Article 11 - Right of Access",
            description: "Data subjects can request access to their personal data",
            order_no: 2,
            summary: "Enable access requests",
            questions: [
              "Is access request process established?",
              "Are requests handled within legal timeframe?",
              "Is data provided in accessible format?"
            ],
            evidence_examples: [
              "Access request procedure",
              "Request handling logs",
              "Response templates"
            ]
          },
          {
            title: "Article 12 - Right to Rectification",
            description: "Data subjects can correct inaccurate or incomplete data",
            order_no: 3,
            summary: "Enable data correction",
            questions: [
              "Can data subjects request corrections?",
              "Are corrections made promptly?",
              "Are third parties notified?"
            ],
            evidence_examples: [
              "Rectification procedure",
              "Correction logs",
              "Third-party notification records"
            ]
          },
          {
            title: "Article 13 - Right to Erasure",
            description: "Data subjects can request deletion of their data",
            order_no: 4,
            summary: "Enable data deletion",
            questions: [
              "Is erasure request process established?",
              "Are deletion criteria documented?",
              "Is data deleted from all systems?"
            ],
            evidence_examples: [
              "Erasure procedure",
              "Deletion verification",
              "System deletion logs"
            ]
          },
          {
            title: "Article 14 - Right to Object",
            description: "Data subjects can object to certain processing activities",
            order_no: 5,
            summary: "Handle objection requests",
            questions: [
              "Can objections be submitted?",
              "Are objections properly assessed?",
              "Is processing stopped when objection is valid?"
            ],
            evidence_examples: [
              "Objection procedure",
              "Assessment records",
              "Processing cessation logs"
            ]
          }
        ]
      },
      {
        title: "Chapter 4: Cross-Border Transfers",
        description: "Requirements for transferring data outside Bahrain",
        order_no: 4,
        items: [
          {
            title: "Article 15 - Transfer Conditions",
            description: "Data transfers outside Bahrain require adequate protection",
            order_no: 1,
            summary: "Control international data transfers",
            questions: [
              "Are all cross-border transfers identified?",
              "Is adequate protection ensured?",
              "Are transfer mechanisms documented?"
            ],
            evidence_examples: [
              "Transfer inventory",
              "Adequacy assessments",
              "Transfer mechanism documentation"
            ]
          },
          {
            title: "Article 16 - Adequate Jurisdictions",
            description: "Transfers to jurisdictions with adequate protection levels",
            order_no: 2,
            summary: "Identify approved transfer destinations",
            questions: [
              "Are transfers limited to adequate jurisdictions?",
              "Is adequacy list maintained?",
              "Are non-adequate transfers justified?"
            ],
            evidence_examples: [
              "Approved jurisdiction list",
              "Adequacy determinations",
              "Exception documentation"
            ]
          },
          {
            title: "Article 17 - Contractual Safeguards",
            description: "Use of contractual clauses for transfers to non-adequate jurisdictions",
            order_no: 3,
            summary: "Implement contractual safeguards",
            questions: [
              "Are approved contractual clauses used?",
              "Are contracts with processors adequate?",
              "Are transfer agreements reviewed regularly?"
            ],
            evidence_examples: [
              "Signed contractual clauses",
              "Data processing agreements",
              "Contract reviews"
            ]
          }
        ]
      },
      {
        title: "Chapter 5: CBB AI Notice (2023)",
        description: "Central Bank of Bahrain requirements for AI use in financial services",
        order_no: 5,
        items: [
          {
            title: "Article 18 - CBB AI Registration",
            description: "Financial institutions must register AI systems with CBB",
            order_no: 1,
            summary: "Register AI systems with Central Bank",
            questions: [
              "Are AI systems registered with CBB?",
              "Is registration kept up to date?",
              "Are material changes reported?"
            ],
            evidence_examples: [
              "CBB AI registration",
              "Registration updates",
              "Change notification records"
            ]
          },
          {
            title: "Article 19 - AI Risk Assessment",
            description: "AI systems in financial services require risk assessment",
            order_no: 2,
            summary: "Conduct AI risk assessments",
            questions: [
              "Are AI risks identified and documented?",
              "Is risk assessment methodology applied?",
              "Are mitigations implemented?"
            ],
            evidence_examples: [
              "AI risk assessment reports",
              "Risk methodology documentation",
              "Mitigation implementation records"
            ]
          },
          {
            title: "Article 20 - Model Governance",
            description: "Governance requirements for AI/ML models in financial services",
            order_no: 3,
            summary: "Implement AI model governance",
            questions: [
              "Is model governance framework in place?",
              "Are models validated before deployment?",
              "Is ongoing monitoring conducted?"
            ],
            evidence_examples: [
              "Model governance framework",
              "Model validation reports",
              "Monitoring procedures"
            ]
          },
          {
            title: "Article 21 - Consumer Protection",
            description: "Protecting consumers from AI-related risks in financial services",
            order_no: 4,
            summary: "Ensure consumer protection for AI",
            questions: [
              "Are consumers informed of AI use?",
              "Is human review available for AI decisions?",
              "Are complaint mechanisms in place?"
            ],
            evidence_examples: [
              "Consumer disclosure notices",
              "Human review procedures",
              "Complaint handling records"
            ]
          },
          {
            title: "Article 22 - Open Banking AI Requirements",
            description: "Specific requirements for AI in Open Banking services",
            order_no: 5,
            summary: "Comply with Open Banking AI rules",
            questions: [
              "Are Open Banking AI rules followed?",
              "Is data sharing AI-compliant?",
              "Are third-party AI systems assessed?"
            ],
            evidence_examples: [
              "Open Banking AI compliance",
              "Data sharing assessments",
              "Third-party AI evaluations"
            ]
          }
        ]
      },
      {
        title: "Chapter 6: EDB AI Ethics Pledge",
        description: "Economic Development Board AI Ethics requirements",
        order_no: 6,
        items: [
          {
            title: "Article 23 - AI Ethics Commitment",
            description: "Organizations should commit to AI ethics principles",
            order_no: 1,
            summary: "Commit to AI ethics standards",
            questions: [
              "Is EDB AI Ethics Pledge signed?",
              "Are ethics principles documented?",
              "Is commitment communicated internally?"
            ],
            evidence_examples: [
              "Signed AI Ethics Pledge",
              "Ethics principles documentation",
              "Internal communications"
            ]
          },
          {
            title: "Article 24 - AI Transparency",
            description: "AI systems must be transparent and explainable",
            order_no: 2,
            summary: "Ensure AI system transparency",
            questions: [
              "Are AI systems documented?",
              "Is decision logic explainable?",
              "Are users informed of AI involvement?"
            ],
            evidence_examples: [
              "AI system documentation",
              "Explainability reports",
              "AI disclosure notices"
            ]
          },
          {
            title: "Article 25 - AI Fairness",
            description: "AI systems must be fair and non-discriminatory",
            order_no: 3,
            summary: "Prevent AI bias and discrimination",
            questions: [
              "Are bias assessments conducted?",
              "Is fairness testing performed?",
              "Are discrimination risks mitigated?"
            ],
            evidence_examples: [
              "Bias assessment reports",
              "Fairness testing results",
              "Mitigation documentation"
            ]
          },
          {
            title: "Article 26 - AI Accountability",
            description: "Clear accountability for AI system outcomes",
            order_no: 4,
            summary: "Establish AI accountability",
            questions: [
              "Is AI governance structure defined?",
              "Are responsibilities assigned?",
              "Is human oversight maintained?"
            ],
            evidence_examples: [
              "AI governance framework",
              "RACI matrix for AI",
              "Human oversight procedures"
            ]
          },
          {
            title: "Article 27 - AI Safety and Security",
            description: "AI systems must be safe and secure",
            order_no: 5,
            summary: "Ensure AI safety and security",
            questions: [
              "Are AI safety assessments conducted?",
              "Are security measures implemented?",
              "Are failure modes addressed?"
            ],
            evidence_examples: [
              "AI safety assessments",
              "Security controls documentation",
              "Failure mode analysis"
            ]
          }
        ]
      },
      {
        title: "Chapter 7: Enforcement and Penalties",
        description: "Regulatory enforcement and penalty provisions",
        order_no: 7,
        items: [
          {
            title: "Article 28 - Breach Notification",
            description: "Data breaches must be notified to Authority and affected individuals",
            order_no: 1,
            summary: "Implement breach notification procedures",
            questions: [
              "Is breach detection capability in place?",
              "Can notification be made timely?",
              "Are affected individuals notified?"
            ],
            evidence_examples: [
              "Breach response plan",
              "Notification templates",
              "Breach register"
            ]
          },
          {
            title: "Article 29 - Regulatory Audits",
            description: "Authority may conduct compliance audits",
            order_no: 2,
            summary: "Prepare for regulatory audits",
            questions: [
              "Is audit readiness maintained?",
              "Are records available for inspection?",
              "Is cooperation with auditors ensured?"
            ],
            evidence_examples: [
              "Audit readiness checklist",
              "Document retention policy",
              "Previous audit records"
            ]
          },
          {
            title: "Article 30 - Administrative Penalties",
            description: "Violations may result in fines and sanctions under Bahrain PDPL",
            order_no: 3,
            summary: "Understand penalty provisions",
            questions: [
              "Are penalty provisions understood?",
              "Are high-risk areas addressed?",
              "Is legal counsel engaged?"
            ],
            evidence_examples: [
              "Penalty risk assessment",
              "Compliance gap remediation",
              "Legal review documentation"
            ]
          },
          {
            title: "Article 31 - CBB Enforcement",
            description: "Central Bank enforcement for financial sector AI violations",
            order_no: 4,
            summary: "Understand CBB enforcement",
            questions: [
              "Are CBB AI requirements met?",
              "Is CBB reporting completed?",
              "Are CBB audits prepared for?"
            ],
            evidence_examples: [
              "CBB compliance attestation",
              "CBB reporting records",
              "CBB audit preparation"
            ]
          }
        ]
      }
    ]
  }
};

// plugins/bahrain-pdpl/index.ts
var plugin = createFrameworkPlugin({
  key: "bahrain-pdpl",
  name: "Bahrain Personal Data Protection Law",
  description: "Bahrain PDPL 30/2018, CBB AI Notice, and EDB AI Ethics Pledge compliance framework.",
  version: "1.0.0",
  author: "VerifyWise",
  template: template_default.framework,
  autoImport: true
});
var { metadata, install, uninstall, validateConfig, router } = plugin;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  install,
  metadata,
  router,
  uninstall,
  validateConfig
});
