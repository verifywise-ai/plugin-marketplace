/**
 * Saudi Arabia Personal Data Protection Law Framework Plugin (Bundled)
 * Generated by build-framework-plugins.js
 */

"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// plugins/saudi-pdpl/index.ts
var index_exports = {};
__export(index_exports, {
  install: () => install,
  metadata: () => metadata,
  router: () => router,
  uninstall: () => uninstall,
  validateConfig: () => validateConfig
});
module.exports = __toCommonJS(index_exports);

// packages/custom-framework-base/index.ts
async function ensureSharedTables(sequelize, tenantId) {
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_frameworks (
      id SERIAL PRIMARY KEY,
      plugin_key VARCHAR(100),
      name VARCHAR(255) NOT NULL,
      description TEXT,
      version VARCHAR(50) DEFAULT '1.0.0',
      is_organizational BOOLEAN DEFAULT FALSE,
      hierarchy_type VARCHAR(50) NOT NULL DEFAULT 'two_level',
      level_1_name VARCHAR(100) NOT NULL DEFAULT 'Category',
      level_2_name VARCHAR(100) NOT NULL DEFAULT 'Control',
      level_3_name VARCHAR(100),
      file_source VARCHAR(100),
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = '${tenantId}'
        AND table_name = 'custom_frameworks'
        AND column_name = 'plugin_key'
      ) THEN
        ALTER TABLE "${tenantId}".custom_frameworks ADD COLUMN plugin_key VARCHAR(100);
      END IF;
    END $$;
  `);
  await sequelize.query(`
    DO $$
    BEGIN
      IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns
        WHERE table_schema = '${tenantId}'
        AND table_name = 'custom_frameworks'
        AND column_name = 'file_source'
      ) THEN
        ALTER TABLE "${tenantId}".custom_frameworks ADD COLUMN file_source VARCHAR(100);
      END IF;
    END $$;
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level1 (
      id SERIAL PRIMARY KEY,
      framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_frameworks(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2 (
      id SERIAL PRIMARY KEY,
      level1_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level1(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      summary TEXT,
      questions TEXT[],
      evidence_examples TEXT[],
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3 (
      id SERIAL PRIMARY KEY,
      level2_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2(id) ON DELETE CASCADE,
      title VARCHAR(500) NOT NULL,
      description TEXT,
      order_no INTEGER NOT NULL DEFAULT 1,
      summary TEXT,
      questions TEXT[],
      evidence_examples TEXT[],
      metadata JSONB DEFAULT '{}',
      created_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_projects (
      id SERIAL PRIMARY KEY,
      framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_frameworks(id) ON DELETE CASCADE,
      project_id INTEGER NOT NULL,
      created_at TIMESTAMP DEFAULT NOW(),
      UNIQUE(framework_id, project_id)
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2_impl (
      id SERIAL PRIMARY KEY,
      level2_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2(id) ON DELETE CASCADE,
      project_framework_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_projects(id) ON DELETE CASCADE,
      status VARCHAR(50) DEFAULT 'Not started',
      owner INTEGER,
      reviewer INTEGER,
      approver INTEGER,
      due_date DATE,
      implementation_details TEXT,
      evidence_links JSONB DEFAULT '[]',
      feedback_links JSONB DEFAULT '[]',
      auditor_feedback TEXT,
      is_demo BOOLEAN DEFAULT FALSE,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3_impl (
      id SERIAL PRIMARY KEY,
      level3_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level3(id) ON DELETE CASCADE,
      level2_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2_impl(id) ON DELETE CASCADE,
      status VARCHAR(50) DEFAULT 'Not started',
      owner INTEGER,
      reviewer INTEGER,
      approver INTEGER,
      due_date DATE,
      implementation_details TEXT,
      evidence_links JSONB DEFAULT '[]',
      feedback_links JSONB DEFAULT '[]',
      auditor_feedback TEXT,
      is_demo BOOLEAN DEFAULT FALSE,
      created_at TIMESTAMP DEFAULT NOW(),
      updated_at TIMESTAMP DEFAULT NOW()
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level2_risks (
      level2_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level2_impl(id) ON DELETE CASCADE,
      risk_id INTEGER NOT NULL,
      PRIMARY KEY (level2_impl_id, risk_id)
    )
  `);
  await sequelize.query(`
    CREATE TABLE IF NOT EXISTS "${tenantId}".custom_framework_level3_risks (
      level3_impl_id INTEGER NOT NULL REFERENCES "${tenantId}".custom_framework_level3_impl(id) ON DELETE CASCADE,
      risk_id INTEGER NOT NULL,
      PRIMARY KEY (level3_impl_id, risk_id)
    )
  `);
  const indexes = [
    `CREATE INDEX IF NOT EXISTS idx_cf_level1_framework ON "${tenantId}".custom_framework_level1(framework_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_level2_level1 ON "${tenantId}".custom_framework_level2(level1_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_level3_level2 ON "${tenantId}".custom_framework_level3(level2_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_l2impl_pf ON "${tenantId}".custom_framework_level2_impl(project_framework_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_l3impl_l2impl ON "${tenantId}".custom_framework_level3_impl(level2_impl_id)`,
    `CREATE INDEX IF NOT EXISTS idx_cf_plugin_key ON "${tenantId}".custom_frameworks(plugin_key)`
  ];
  for (const idx of indexes) {
    await sequelize.query(idx);
  }
}
function toPgArray(arr) {
  if (!arr || arr.length === 0) return "{}";
  const escaped = arr.map((item) => {
    const escapedItem = String(item).replace(/\\/g, "\\\\").replace(/"/g, '\\"');
    return `"${escapedItem}"`;
  });
  return `{${escaped.join(",")}}`;
}
function generateFileSourceName(frameworkName) {
  const cleanName = frameworkName.trim();
  return `${cleanName} evidence`;
}
async function addFileSourceEnum(sequelize, sourceName) {
  try {
    const [existing] = await sequelize.query(
      `
      SELECT 1 FROM pg_enum
      WHERE enumtypid = (SELECT oid FROM pg_type WHERE typname = 'enum_files_source')
      AND enumlabel = :sourceName
    `,
      { replacements: { sourceName } }
    );
    if (existing.length === 0) {
      await sequelize.query(
        `ALTER TYPE public.enum_files_source ADD VALUE '${sourceName.replace(/'/g, "''")}'`
      );
      console.log(`[CustomFrameworkBase] Added file source enum: "${sourceName}"`);
    }
    return true;
  } catch (error) {
    console.error(`[CustomFrameworkBase] Failed to add file source enum: ${error.message}`);
    return false;
  }
}
async function importFramework(frameworkData, tenantId, sequelize, pluginKey) {
  const fileSource = generateFileSourceName(frameworkData.name);
  await addFileSourceEnum(sequelize, fileSource);
  const transaction = await sequelize.transaction();
  try {
    const [frameworkResult] = await sequelize.query(
      `INSERT INTO "${tenantId}".custom_frameworks
       (plugin_key, name, description, version, is_organizational, hierarchy_type, level_1_name, level_2_name, level_3_name, file_source, created_at)
       VALUES (:plugin_key, :name, :description, :version, :is_organizational, :hierarchy_type, :level_1_name, :level_2_name, :level_3_name, :file_source, NOW())
       RETURNING id`,
      {
        replacements: {
          plugin_key: pluginKey,
          name: frameworkData.name,
          description: frameworkData.description,
          version: frameworkData.version || "1.0.0",
          is_organizational: frameworkData.is_organizational,
          hierarchy_type: frameworkData.hierarchy.type,
          level_1_name: frameworkData.hierarchy.level1_name,
          level_2_name: frameworkData.hierarchy.level2_name,
          level_3_name: frameworkData.hierarchy.level3_name || null,
          file_source: fileSource
        },
        transaction
      }
    );
    const frameworkId = frameworkResult[0].id;
    let itemsCreated = 0;
    for (const level1 of frameworkData.structure) {
      const [level1Result] = await sequelize.query(
        `INSERT INTO "${tenantId}".custom_framework_level1
         (framework_id, title, description, order_no, metadata)
         VALUES (:framework_id, :title, :description, :order_no, :metadata)
         RETURNING id`,
        {
          replacements: {
            framework_id: frameworkId,
            title: level1.title,
            description: level1.description || null,
            order_no: level1.order_no,
            metadata: JSON.stringify(level1.metadata || {})
          },
          transaction
        }
      );
      const level1Id = level1Result[0].id;
      itemsCreated++;
      for (const level2 of level1.items || []) {
        const [level2Result] = await sequelize.query(
          `INSERT INTO "${tenantId}".custom_framework_level2
           (level1_id, title, description, order_no, summary, questions, evidence_examples, metadata)
           VALUES (:level1_id, :title, :description, :order_no, :summary, :questions, :evidence_examples, :metadata)
           RETURNING id`,
          {
            replacements: {
              level1_id: level1Id,
              title: level2.title,
              description: level2.description || null,
              order_no: level2.order_no,
              summary: level2.summary || null,
              questions: toPgArray(level2.questions),
              evidence_examples: toPgArray(level2.evidence_examples),
              metadata: JSON.stringify(level2.metadata || {})
            },
            transaction
          }
        );
        const level2Id = level2Result[0].id;
        itemsCreated++;
        if (frameworkData.hierarchy.type === "three_level" && level2.items) {
          for (const level3 of level2.items) {
            await sequelize.query(
              `INSERT INTO "${tenantId}".custom_framework_level3
               (level2_id, title, description, order_no, summary, questions, evidence_examples, metadata)
               VALUES (:level2_id, :title, :description, :order_no, :summary, :questions, :evidence_examples, :metadata)`,
              {
                replacements: {
                  level2_id: level2Id,
                  title: level3.title,
                  description: level3.description || null,
                  order_no: level3.order_no,
                  summary: level3.summary || null,
                  questions: toPgArray(level3.questions),
                  evidence_examples: toPgArray(level3.evidence_examples),
                  metadata: JSON.stringify(level3.metadata || {})
                },
                transaction
              }
            );
            itemsCreated++;
          }
        }
      }
    }
    await transaction.commit();
    return { frameworkId, itemsCreated, fileSource };
  } catch (error) {
    await transaction.rollback();
    throw error;
  }
}
function createRouteHandlers(pluginKey, config) {
  async function handleGetFrameworks(ctx) {
    const { sequelize, tenantId, query } = ctx;
    const showAll = query.all === "true";
    try {
      const whereClause = showAll ? "1=1" : "cf.plugin_key = :pluginKey OR cf.plugin_key IS NULL";
      const [frameworks] = await sequelize.query(
        `
        SELECT
          cf.id,
          cf.plugin_key,
          cf.name,
          cf.description,
          cf.version,
          cf.is_organizational,
          cf.hierarchy_type,
          cf.level_1_name,
          cf.level_2_name,
          cf.level_3_name,
          cf.file_source,
          cf.created_at,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level1 WHERE framework_id = cf.id) as level1_count,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level2 l2
           JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
           WHERE l1.framework_id = cf.id) as level2_count,
          (SELECT COUNT(*) FROM "${tenantId}".custom_framework_level3 l3
           JOIN "${tenantId}".custom_framework_level2 l2 ON l3.level2_id = l2.id
           JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
           WHERE l1.framework_id = cf.id) as level3_count
        FROM "${tenantId}".custom_frameworks cf
        WHERE ${whereClause}
        ORDER BY cf.created_at DESC
      `,
        { replacements: { pluginKey } }
      );
      return { status: 200, data: frameworks };
    } catch (error) {
      return { status: 500, data: { message: `Failed to fetch frameworks: ${error.message}` } };
    }
  }
  async function handleGetFrameworkById(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [meta] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (meta.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const [level1Items] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_framework_level1
         WHERE framework_id = :frameworkId ORDER BY order_no`,
        { replacements: { frameworkId } }
      );
      for (const l1 of level1Items) {
        const [level2Items] = await sequelize.query(
          `SELECT * FROM "${tenantId}".custom_framework_level2
           WHERE level1_id = :level1Id ORDER BY order_no`,
          { replacements: { level1Id: l1.id } }
        );
        for (const l2 of level2Items) {
          if (meta[0].hierarchy_type === "three_level") {
            const [level3Items] = await sequelize.query(
              `SELECT * FROM "${tenantId}".custom_framework_level3
               WHERE level2_id = :level2Id ORDER BY order_no`,
              { replacements: { level2Id: l2.id } }
            );
            l2.items = level3Items;
          }
        }
        l1.items = level2Items;
      }
      const [linkedProjectsRaw] = await sequelize.query(
        `SELECT
          cfp.id as project_framework_id,
          cfp.project_id,
          cfp.created_at as added_at,
          p.project_title,
          COALESCE(p.is_organizational, false) as is_organizational
        FROM "${tenantId}".custom_framework_projects cfp
        JOIN "${tenantId}".projects p ON cfp.project_id = p.id
        WHERE cfp.framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      const linkedProjects = await Promise.all(
        linkedProjectsRaw.map(async (proj) => {
          let progressData;
          if (meta[0].hierarchy_type === "three_level") {
            [progressData] = await sequelize.query(
              `SELECT
                COUNT(*) as total,
                SUM(CASE WHEN l3.status = 'Implemented' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN l3.owner IS NOT NULL THEN 1 ELSE 0 END) as assigned
              FROM "${tenantId}".custom_framework_level3_impl l3
              JOIN "${tenantId}".custom_framework_level2_impl l2 ON l3.level2_impl_id = l2.id
              WHERE l2.project_framework_id = :projectFrameworkId`,
              { replacements: { projectFrameworkId: proj.project_framework_id } }
            );
          } else {
            [progressData] = await sequelize.query(
              `SELECT
                COUNT(*) as total,
                SUM(CASE WHEN status = 'Implemented' THEN 1 ELSE 0 END) as completed,
                SUM(CASE WHEN owner IS NOT NULL THEN 1 ELSE 0 END) as assigned
              FROM "${tenantId}".custom_framework_level2_impl
              WHERE project_framework_id = :projectFrameworkId`,
              { replacements: { projectFrameworkId: proj.project_framework_id } }
            );
          }
          const total = parseInt(progressData[0]?.total || "0");
          const completed = parseInt(progressData[0]?.completed || "0");
          const assigned = parseInt(progressData[0]?.assigned || "0");
          return {
            project_framework_id: proj.project_framework_id,
            project_id: proj.project_id,
            project_title: proj.project_title,
            is_organizational: proj.is_organizational,
            added_at: proj.added_at,
            progress: {
              total,
              completed,
              assigned,
              percentage: total > 0 ? Math.round(completed / total * 100) : 0
            }
          };
        })
      );
      return {
        status: 200,
        data: {
          ...meta[0],
          structure: level1Items,
          linkedProjects
        }
      };
    } catch (error) {
      return { status: 500, data: { message: `Failed to fetch structure: ${error.message}` } };
    }
  }
  async function handleDeleteFramework(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [framework] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (framework.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const [projects] = await sequelize.query(
        `SELECT COUNT(*) as count FROM "${tenantId}".custom_framework_projects WHERE framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (parseInt(projects[0].count) > 0) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_projects WHERE framework_id = :frameworkId`,
          { replacements: { frameworkId } }
        );
      }
      await sequelize.query(`DELETE FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`, {
        replacements: { frameworkId }
      });
      return { status: 200, data: { success: true, message: "Framework deleted" } };
    } catch (error) {
      return { status: 500, data: { message: `Delete failed: ${error.message}` } };
    }
  }
  async function handleAddToProject(ctx) {
    const { sequelize, tenantId, body } = ctx;
    const { frameworkId, projectId } = body;
    if (!frameworkId || !projectId) {
      return { status: 400, data: { message: "frameworkId and projectId are required" } };
    }
    try {
      const [framework] = await sequelize.query(
        `SELECT id, hierarchy_type FROM "${tenantId}".custom_frameworks WHERE id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      if (framework.length === 0) {
        return { status: 404, data: { message: "Framework not found" } };
      }
      const hierarchyType = framework[0].hierarchy_type;
      const [existing] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_projects
         WHERE framework_id = :frameworkId AND project_id = :projectId`,
        { replacements: { frameworkId, projectId } }
      );
      if (existing.length > 0) {
        return { status: 400, data: { message: "Framework already added to this project" } };
      }
      const [insertResult] = await sequelize.query(
        `INSERT INTO "${tenantId}".custom_framework_projects (framework_id, project_id, created_at)
         VALUES (:frameworkId, :projectId, NOW())
         RETURNING id`,
        { replacements: { frameworkId, projectId } }
      );
      const projectFrameworkId = insertResult[0].id;
      const [level2Items] = await sequelize.query(
        `SELECT l2.id FROM "${tenantId}".custom_framework_level2 l2
         JOIN "${tenantId}".custom_framework_level1 l1 ON l2.level1_id = l1.id
         WHERE l1.framework_id = :frameworkId`,
        { replacements: { frameworkId } }
      );
      for (const l2 of level2Items) {
        const [implResult] = await sequelize.query(
          `INSERT INTO "${tenantId}".custom_framework_level2_impl
           (level2_id, project_framework_id, status, created_at, updated_at)
           VALUES (:level2_id, :project_framework_id, 'Not started', NOW(), NOW())
           RETURNING id`,
          { replacements: { level2_id: l2.id, project_framework_id: projectFrameworkId } }
        );
        if (hierarchyType === "three_level") {
          const [level3Items] = await sequelize.query(
            `SELECT id FROM "${tenantId}".custom_framework_level3 WHERE level2_id = :level2Id`,
            { replacements: { level2Id: l2.id } }
          );
          for (const l3 of level3Items) {
            await sequelize.query(
              `INSERT INTO "${tenantId}".custom_framework_level3_impl
               (level3_id, level2_impl_id, status, created_at, updated_at)
               VALUES (:level3_id, :level2_impl_id, 'Not started', NOW(), NOW())`,
              { replacements: { level3_id: l3.id, level2_impl_id: implResult[0].id } }
            );
          }
        }
      }
      return {
        status: 200,
        data: { success: true, message: "Framework added to project", projectFrameworkId }
      };
    } catch (error) {
      return { status: 500, data: { message: `Failed to add: ${error.message}` } };
    }
  }
  async function handleRemoveFromProject(ctx) {
    const { sequelize, tenantId, body } = ctx;
    const { frameworkId, projectId } = body;
    if (!frameworkId || !projectId) {
      return { status: 400, data: { message: "frameworkId and projectId are required" } };
    }
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".custom_framework_projects
         WHERE framework_id = :frameworkId AND project_id = :projectId`,
        { replacements: { frameworkId, projectId } }
      );
      return { status: 200, data: { success: true, message: "Framework removed from project" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to remove: ${error.message}` } };
    }
  }
  async function handleGetProjectFrameworks(ctx) {
    const { sequelize, tenantId, params, query } = ctx;
    const projectId = parseInt(params.projectId);
    const isOrganizational = query.is_organizational === "true";
    try {
      const [frameworks] = await sequelize.query(
        `
        SELECT cf.*, cf.id as framework_id, cfp.id as project_framework_id, cfp.created_at as added_at
        FROM "${tenantId}".custom_frameworks cf
        JOIN "${tenantId}".custom_framework_projects cfp ON cf.id = cfp.framework_id
        WHERE cfp.project_id = :projectId
        ORDER BY cf.name
      `,
        { replacements: { projectId } }
      );
      return { status: 200, data: frameworks };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleGetProjectFramework(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const projectId = parseInt(params.projectId);
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [projectFramework] = await sequelize.query(
        `SELECT cfp.id as project_framework_id, cf.*
         FROM "${tenantId}".custom_framework_projects cfp
         JOIN "${tenantId}".custom_frameworks cf ON cfp.framework_id = cf.id
         WHERE cfp.project_id = :projectId AND cfp.framework_id = :frameworkId`,
        { replacements: { projectId, frameworkId } }
      );
      if (projectFramework.length === 0) {
        return { status: 404, data: { message: "Framework not found in project" } };
      }
      const pf = projectFramework[0];
      const projectFrameworkId = pf.project_framework_id;
      const [level1Items] = await sequelize.query(
        `SELECT * FROM "${tenantId}".custom_framework_level1
         WHERE framework_id = :frameworkId ORDER BY order_no`,
        { replacements: { frameworkId } }
      );
      for (const l1 of level1Items) {
        const [level2Items] = await sequelize.query(
          `SELECT l2.*,
                  impl.id as impl_id, impl.status, impl.owner, impl.reviewer, impl.approver,
                  impl.due_date, impl.implementation_details, impl.evidence_links,
                  impl.feedback_links, impl.auditor_feedback,
                  u_owner.name as owner_name, u_owner.surname as owner_surname,
                  u_reviewer.name as reviewer_name, u_reviewer.surname as reviewer_surname,
                  u_approver.name as approver_name, u_approver.surname as approver_surname
           FROM "${tenantId}".custom_framework_level2 l2
           LEFT JOIN "${tenantId}".custom_framework_level2_impl impl
             ON l2.id = impl.level2_id AND impl.project_framework_id = :projectFrameworkId
           LEFT JOIN public.users u_owner ON impl.owner = u_owner.id
           LEFT JOIN public.users u_reviewer ON impl.reviewer = u_reviewer.id
           LEFT JOIN public.users u_approver ON impl.approver = u_approver.id
           WHERE l2.level1_id = :level1Id
           ORDER BY l2.order_no`,
          { replacements: { level1Id: l1.id, projectFrameworkId } }
        );
        for (const l2 of level2Items) {
          if (l2.impl_id) {
            const [risks] = await sequelize.query(
              `SELECT r.id, r.risk_name, r.risk_description
               FROM "${tenantId}".custom_framework_level2_risks lr
               JOIN "${tenantId}".risks r ON lr.risk_id = r.id
               WHERE lr.level2_impl_id = :implId`,
              { replacements: { implId: l2.impl_id } }
            );
            l2.linked_risks = risks;
            const [linkedFiles] = await sequelize.query(
              `SELECT
                f.id,
                f.filename,
                f.size,
                f.type as mimetype,
                f.uploaded_time as upload_date,
                u.name as uploader_name,
                u.surname as uploader_surname,
                fel.link_type
              FROM "${tenantId}".file_entity_links fel
              JOIN "${tenantId}".files f ON fel.file_id = f.id
              LEFT JOIN public.users u ON f.uploaded_by = u.id
              WHERE fel.framework_type = :frameworkType
                AND fel.entity_type = 'level2_impl'
                AND fel.entity_id = :implId
              ORDER BY fel.created_at DESC`,
              { replacements: { frameworkType: pluginKey, implId: l2.impl_id } }
            );
            l2.linked_files = linkedFiles;
          } else {
            l2.linked_risks = [];
            l2.linked_files = [];
          }
          if (pf.hierarchy_type === "three_level") {
            const [level3Items] = await sequelize.query(
              `SELECT l3.*,
                      impl.id as impl_id, impl.status, impl.owner, impl.reviewer, impl.approver,
                      impl.due_date, impl.implementation_details, impl.evidence_links
               FROM "${tenantId}".custom_framework_level3 l3
               LEFT JOIN "${tenantId}".custom_framework_level3_impl impl
                 ON l3.id = impl.level3_id AND impl.level2_impl_id = :level2ImplId
               WHERE l3.level2_id = :level2Id
               ORDER BY l3.order_no`,
              { replacements: { level2Id: l2.id, level2ImplId: l2.impl_id } }
            );
            for (const l3 of level3Items) {
              if (l3.impl_id) {
                const [l3Files] = await sequelize.query(
                  `SELECT
                    f.id,
                    f.filename,
                    f.size,
                    f.type as mimetype,
                    f.uploaded_time as upload_date,
                    u.name as uploader_name,
                    u.surname as uploader_surname,
                    fel.link_type
                  FROM "${tenantId}".file_entity_links fel
                  JOIN "${tenantId}".files f ON fel.file_id = f.id
                  LEFT JOIN public.users u ON f.uploaded_by = u.id
                  WHERE fel.framework_type = :frameworkType
                    AND fel.entity_type = 'level3_impl'
                    AND fel.entity_id = :implId
                  ORDER BY fel.created_at DESC`,
                  { replacements: { frameworkType: pluginKey, implId: l3.impl_id } }
                );
                l3.linked_files = l3Files;
              } else {
                l3.linked_files = [];
              }
            }
            l2.items = level3Items;
          }
        }
        l1.items = level2Items;
      }
      return {
        status: 200,
        data: {
          projectFrameworkId,
          frameworkId: pf.id,
          name: pf.name,
          description: pf.description,
          is_organizational: pf.is_organizational,
          hierarchy_type: pf.hierarchy_type,
          level_1_name: pf.level_1_name,
          level_2_name: pf.level_2_name,
          level_3_name: pf.level_3_name,
          file_source: pf.file_source,
          structure: level1Items
        }
      };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleGetProgress(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const projectId = parseInt(params.projectId);
    const frameworkId = parseInt(params.frameworkId);
    try {
      const [projectFramework] = await sequelize.query(
        `SELECT cfp.id as project_framework_id, cf.hierarchy_type
         FROM "${tenantId}".custom_framework_projects cfp
         JOIN "${tenantId}".custom_frameworks cf ON cfp.framework_id = cf.id
         WHERE cfp.project_id = :projectId AND cfp.framework_id = :frameworkId`,
        { replacements: { projectId, frameworkId } }
      );
      if (projectFramework.length === 0) {
        return { status: 404, data: { message: "Framework not found in project" } };
      }
      const projectFrameworkId = projectFramework[0].project_framework_id;
      const hierarchyType = projectFramework[0].hierarchy_type;
      const [level2Stats] = await sequelize.query(
        `SELECT
           COUNT(*) as total,
           COUNT(CASE WHEN status = 'Implemented' THEN 1 END) as completed,
           COUNT(CASE WHEN owner IS NOT NULL THEN 1 END) as assigned
         FROM "${tenantId}".custom_framework_level2_impl
         WHERE project_framework_id = :projectFrameworkId`,
        { replacements: { projectFrameworkId } }
      );
      const result = {
        level2: {
          total: parseInt(level2Stats[0].total),
          completed: parseInt(level2Stats[0].completed),
          assigned: parseInt(level2Stats[0].assigned),
          percentage: parseInt(level2Stats[0].total) > 0 ? Math.round(
            parseInt(level2Stats[0].completed) / parseInt(level2Stats[0].total) * 100
          ) : 0
        }
      };
      if (hierarchyType === "three_level") {
        const [level3Stats] = await sequelize.query(
          `SELECT
             COUNT(*) as total,
             COUNT(CASE WHEN l3.status = 'Implemented' THEN 1 END) as completed,
             COUNT(CASE WHEN l3.owner IS NOT NULL THEN 1 END) as assigned
           FROM "${tenantId}".custom_framework_level3_impl l3
           JOIN "${tenantId}".custom_framework_level2_impl l2 ON l3.level2_impl_id = l2.id
           WHERE l2.project_framework_id = :projectFrameworkId`,
          { replacements: { projectFrameworkId } }
        );
        result.level3 = {
          total: parseInt(level3Stats[0].total),
          completed: parseInt(level3Stats[0].completed),
          assigned: parseInt(level3Stats[0].assigned),
          percentage: parseInt(level3Stats[0].total) > 0 ? Math.round(
            parseInt(level3Stats[0].completed) / parseInt(level3Stats[0].total) * 100
          ) : 0
        };
        result.overall = result.level3;
      } else {
        result.overall = result.level2;
      }
      return { status: 200, data: result };
    } catch (error) {
      return { status: 500, data: { message: error.message } };
    }
  }
  async function handleUpdateLevel2(ctx) {
    const { sequelize, tenantId, params, body } = ctx;
    const implId = parseInt(params.level2Id);
    try {
      const updateFields = [];
      const replacements = { id: implId };
      const allowedFields = [
        "status",
        "owner",
        "reviewer",
        "approver",
        "due_date",
        "implementation_details",
        "evidence_links",
        "feedback_links",
        "auditor_feedback"
      ];
      for (const field of allowedFields) {
        if (body[field] !== void 0) {
          if (field === "evidence_links" || field === "feedback_links") {
            updateFields.push(`${field} = :${field}::jsonb`);
            replacements[field] = JSON.stringify(body[field]);
          } else if (field === "due_date" && body[field] === null) {
            updateFields.push(`${field} = NULL`);
          } else {
            updateFields.push(`${field} = :${field}`);
            replacements[field] = body[field];
          }
        }
      }
      if (updateFields.length === 0) {
        return { status: 400, data: { message: "No fields to update" } };
      }
      updateFields.push("updated_at = NOW()");
      await sequelize.query(
        `UPDATE "${tenantId}".custom_framework_level2_impl
         SET ${updateFields.join(", ")}
         WHERE id = :id`,
        { replacements }
      );
      if (body.risks_to_add && Array.isArray(body.risks_to_add)) {
        for (const riskId of body.risks_to_add) {
          await sequelize.query(
            `INSERT INTO "${tenantId}".custom_framework_level2_risks (level2_impl_id, risk_id)
             VALUES (:implId, :riskId)
             ON CONFLICT DO NOTHING`,
            { replacements: { implId, riskId } }
          );
        }
      }
      if (body.risks_to_remove && Array.isArray(body.risks_to_remove)) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_level2_risks
           WHERE level2_impl_id = :implId AND risk_id = ANY(:risks)`,
          { replacements: { implId, risks: body.risks_to_remove } }
        );
      }
      return { status: 200, data: { success: true, message: "Updated successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Update failed: ${error.message}` } };
    }
  }
  async function handleUpdateLevel3(ctx) {
    const { sequelize, tenantId, params, body } = ctx;
    const implId = parseInt(params.level3Id);
    try {
      const updateFields = [];
      const replacements = { id: implId };
      const allowedFields = [
        "status",
        "owner",
        "reviewer",
        "approver",
        "due_date",
        "implementation_details",
        "evidence_links",
        "feedback_links",
        "auditor_feedback"
      ];
      for (const field of allowedFields) {
        if (body[field] !== void 0) {
          if (field === "evidence_links" || field === "feedback_links") {
            updateFields.push(`${field} = :${field}::jsonb`);
            replacements[field] = JSON.stringify(body[field]);
          } else if (field === "due_date" && body[field] === null) {
            updateFields.push(`${field} = NULL`);
          } else {
            updateFields.push(`${field} = :${field}`);
            replacements[field] = body[field];
          }
        }
      }
      if (updateFields.length === 0) {
        return { status: 400, data: { message: "No fields to update" } };
      }
      updateFields.push("updated_at = NOW()");
      await sequelize.query(
        `UPDATE "${tenantId}".custom_framework_level3_impl
         SET ${updateFields.join(", ")}
         WHERE id = :id`,
        { replacements }
      );
      return { status: 200, data: { success: true, message: "Updated successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Update failed: ${error.message}` } };
    }
  }
  async function handleAttachFilesToLevel2(ctx) {
    const { sequelize, tenantId, userId, params, body } = ctx;
    const implId = parseInt(params.level2Id);
    const { file_ids, link_type = "evidence" } = body;
    if (!file_ids || !Array.isArray(file_ids) || file_ids.length === 0) {
      return { status: 400, data: { message: "file_ids array is required" } };
    }
    try {
      const [impl] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_level2_impl WHERE id = :implId`,
        { replacements: { implId } }
      );
      if (impl.length === 0) {
        return { status: 404, data: { message: "Implementation record not found" } };
      }
      const results = [];
      for (const fileId of file_ids) {
        try {
          await sequelize.query(
            `INSERT INTO "${tenantId}".file_entity_links
             (file_id, framework_type, entity_type, entity_id, link_type, created_by, created_at)
             VALUES (:fileId, :frameworkType, 'level2_impl', :entityId, :linkType, :userId, NOW())
             ON CONFLICT (file_id, framework_type, entity_type, entity_id) DO NOTHING`,
            {
              replacements: {
                fileId,
                frameworkType: pluginKey,
                entityId: implId,
                linkType: link_type,
                userId
              }
            }
          );
          results.push({ file_id: fileId, success: true, message: "Attached" });
        } catch (err) {
          results.push({ file_id: fileId, success: false, message: err.message });
        }
      }
      return { status: 200, data: { message: "Files attached", results } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to attach files: ${error.message}` } };
    }
  }
  async function handleGetLevel2Files(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level2Id);
    try {
      const [files] = await sequelize.query(
        `SELECT
          f.id,
          f.filename,
          f.size,
          f.type as mimetype,
          f.uploaded_time as upload_date,
          f.uploaded_by,
          u.name as uploader_name,
          u.surname as uploader_surname,
          fel.link_type,
          fel.created_at as linked_at
        FROM "${tenantId}".file_entity_links fel
        JOIN "${tenantId}".files f ON fel.file_id = f.id
        LEFT JOIN public.users u ON f.uploaded_by = u.id
        WHERE fel.framework_type = :frameworkType
          AND fel.entity_type = 'level2_impl'
          AND fel.entity_id = :entityId
        ORDER BY fel.created_at DESC`,
        {
          replacements: {
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: files };
    } catch (error) {
      return { status: 500, data: { message: `Failed to get files: ${error.message}` } };
    }
  }
  async function handleDetachFileFromLevel2(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level2Id);
    const fileId = parseInt(params.fileId);
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".file_entity_links
         WHERE file_id = :fileId
           AND framework_type = :frameworkType
           AND entity_type = 'level2_impl'
           AND entity_id = :entityId`,
        {
          replacements: {
            fileId,
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: { message: "File detached successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to detach file: ${error.message}` } };
    }
  }
  async function handleAttachFilesToLevel3(ctx) {
    const { sequelize, tenantId, userId, params, body } = ctx;
    const implId = parseInt(params.level3Id);
    const { file_ids, link_type = "evidence" } = body;
    if (!file_ids || !Array.isArray(file_ids) || file_ids.length === 0) {
      return { status: 400, data: { message: "file_ids array is required" } };
    }
    try {
      const [impl] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_framework_level3_impl WHERE id = :implId`,
        { replacements: { implId } }
      );
      if (impl.length === 0) {
        return { status: 404, data: { message: "Implementation record not found" } };
      }
      const results = [];
      for (const fileId of file_ids) {
        try {
          await sequelize.query(
            `INSERT INTO "${tenantId}".file_entity_links
             (file_id, framework_type, entity_type, entity_id, link_type, created_by, created_at)
             VALUES (:fileId, :frameworkType, 'level3_impl', :entityId, :linkType, :userId, NOW())
             ON CONFLICT (file_id, framework_type, entity_type, entity_id) DO NOTHING`,
            {
              replacements: {
                fileId,
                frameworkType: pluginKey,
                entityId: implId,
                linkType: link_type,
                userId
              }
            }
          );
          results.push({ file_id: fileId, success: true, message: "Attached" });
        } catch (err) {
          results.push({ file_id: fileId, success: false, message: err.message });
        }
      }
      return { status: 200, data: { message: "Files attached", results } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to attach files: ${error.message}` } };
    }
  }
  async function handleGetLevel3Files(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level3Id);
    try {
      const [files] = await sequelize.query(
        `SELECT
          f.id,
          f.filename,
          f.size,
          f.type as mimetype,
          f.uploaded_time as upload_date,
          f.uploaded_by,
          u.name as uploader_name,
          u.surname as uploader_surname,
          fel.link_type,
          fel.created_at as linked_at
        FROM "${tenantId}".file_entity_links fel
        JOIN "${tenantId}".files f ON fel.file_id = f.id
        LEFT JOIN public.users u ON f.uploaded_by = u.id
        WHERE fel.framework_type = :frameworkType
          AND fel.entity_type = 'level3_impl'
          AND fel.entity_id = :entityId
        ORDER BY fel.created_at DESC`,
        {
          replacements: {
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: files };
    } catch (error) {
      return { status: 500, data: { message: `Failed to get files: ${error.message}` } };
    }
  }
  async function handleDetachFileFromLevel3(ctx) {
    const { sequelize, tenantId, params } = ctx;
    const implId = parseInt(params.level3Id);
    const fileId = parseInt(params.fileId);
    try {
      await sequelize.query(
        `DELETE FROM "${tenantId}".file_entity_links
         WHERE file_id = :fileId
           AND framework_type = :frameworkType
           AND entity_type = 'level3_impl'
           AND entity_id = :entityId`,
        {
          replacements: {
            fileId,
            frameworkType: pluginKey,
            entityId: implId
          }
        }
      );
      return { status: 200, data: { message: "File detached successfully" } };
    } catch (error) {
      return { status: 500, data: { message: `Failed to detach file: ${error.message}` } };
    }
  }
  return {
    handleGetFrameworks,
    handleGetFrameworkById,
    handleDeleteFramework,
    handleAddToProject,
    handleRemoveFromProject,
    handleGetProjectFrameworks,
    handleGetProjectFramework,
    handleGetProgress,
    handleUpdateLevel2,
    handleUpdateLevel3,
    // File attachment handlers
    handleAttachFilesToLevel2,
    handleGetLevel2Files,
    handleDetachFileFromLevel2,
    handleAttachFilesToLevel3,
    handleGetLevel3Files,
    handleDetachFileFromLevel3
  };
}
function createFrameworkPlugin(config) {
  const pluginKey = config.key;
  const metadata2 = {
    name: config.name,
    version: config.version || "1.0.0",
    author: config.author || "VerifyWise",
    description: config.description
  };
  async function install2(_userId, tenantId, _config, context) {
    const { sequelize } = context;
    try {
      await ensureSharedTables(sequelize, tenantId);
      if (config.autoImport !== false && config.template) {
        const [existing] = await sequelize.query(
          `SELECT id FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
          { replacements: { pluginKey } }
        );
        if (existing.length === 0) {
          const result = await importFramework(config.template, tenantId, sequelize, pluginKey);
          console.log(
            `[${config.name}] Auto-imported framework with ${result.itemsCreated} items`
          );
        }
      }
      return {
        success: true,
        message: `${config.name} plugin installed successfully.`,
        installedAt: (/* @__PURE__ */ new Date()).toISOString()
      };
    } catch (error) {
      throw new Error(`Installation failed: ${error.message}`);
    }
  }
  async function uninstall2(_userId, tenantId, context) {
    const { sequelize } = context;
    try {
      const [frameworks] = await sequelize.query(
        `SELECT id FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
        { replacements: { pluginKey } }
      );
      const frameworkIds = frameworks.map((f) => f.id);
      if (frameworkIds.length > 0) {
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_framework_projects WHERE framework_id IN (:ids)`,
          { replacements: { ids: frameworkIds } }
        );
        await sequelize.query(
          `DELETE FROM "${tenantId}".custom_frameworks WHERE plugin_key = :pluginKey`,
          { replacements: { pluginKey } }
        );
      }
      return {
        success: true,
        message: `${config.name} plugin uninstalled successfully.`,
        uninstalledAt: (/* @__PURE__ */ new Date()).toISOString()
      };
    } catch (error) {
      throw new Error(`Uninstall failed: ${error.message}`);
    }
  }
  function validateConfig2(_config) {
    return { valid: true, errors: [] };
  }
  const handlers = createRouteHandlers(pluginKey, config);
  const router2 = {
    "GET /frameworks": handlers.handleGetFrameworks,
    "GET /frameworks/:frameworkId": handlers.handleGetFrameworkById,
    "DELETE /frameworks/:frameworkId": handlers.handleDeleteFramework,
    "POST /add-to-project": handlers.handleAddToProject,
    "POST /remove-from-project": handlers.handleRemoveFromProject,
    "GET /projects/:projectId/custom-frameworks": handlers.handleGetProjectFrameworks,
    "GET /projects/:projectId/frameworks/:frameworkId": handlers.handleGetProjectFramework,
    "GET /projects/:projectId/frameworks/:frameworkId/progress": handlers.handleGetProgress,
    "PATCH /level2/:level2Id": handlers.handleUpdateLevel2,
    "PATCH /level3/:level3Id": handlers.handleUpdateLevel3,
    // File attachment routes for level2 implementations
    "POST /level2/:level2Id/files": handlers.handleAttachFilesToLevel2,
    "GET /level2/:level2Id/files": handlers.handleGetLevel2Files,
    "DELETE /level2/:level2Id/files/:fileId": handlers.handleDetachFileFromLevel2,
    // File attachment routes for level3 implementations
    "POST /level3/:level3Id/files": handlers.handleAttachFilesToLevel3,
    "GET /level3/:level3Id/files": handlers.handleGetLevel3Files,
    "DELETE /level3/:level3Id/files/:fileId": handlers.handleDetachFileFromLevel3
  };
  return {
    metadata: metadata2,
    install: install2,
    uninstall: uninstall2,
    validateConfig: validateConfig2,
    router: router2
  };
}

// plugins/saudi-pdpl/template.json
var template_default = {
  id: "saudi-pdpl",
  name: "Saudi Arabia Personal Data Protection Law",
  description: "Saudi Arabia PDPL and SDAIA AI governance compliance framework.",
  category: "Privacy",
  tags: ["Saudi Arabia", "PDPL", "SDAIA", "Privacy", "Data Protection", "Gulf", "AI"],
  framework: {
    name: "Saudi Arabia Personal Data Protection Law",
    description: "Framework for compliance with Saudi PDPL (since September 2023), SDAIA Ethics Principles, and Generative AI Guidelines (2024)",
    version: "1.0.0",
    is_organizational: true,
    hierarchy: {
      type: "two_level",
      level1_name: "Chapter",
      level2_name: "Article"
    },
    structure: [
      {
        title: "Chapter 1: General Provisions",
        description: "Definitions, scope, and applicability of Saudi PDPL",
        order_no: 1,
        items: [
          {
            title: "Article 1 - Definitions",
            description: "Key definitions including personal data, sensitive data, controller, processor, and explicit consent",
            order_no: 1,
            summary: "Establish definitions per Saudi PDPL",
            questions: [
              "Are personal data types identified per Saudi PDPL?",
              "Is sensitive data categorized correctly?",
              "Are controller/processor roles defined?"
            ],
            evidence_examples: [
              "Data classification policy",
              "Sensitive data inventory",
              "Role definitions document"
            ]
          },
          {
            title: "Article 2 - Territorial Scope",
            description: "Law applies to processing in Saudi Arabia and processing of Saudi residents' data",
            order_no: 2,
            summary: "Define territorial application",
            questions: [
              "Is domestic processing documented?",
              "Are extraterritorial activities identified?",
              "Are exemptions properly applied?"
            ],
            evidence_examples: [
              "Processing inventory",
              "Territorial scope assessment",
              "Exemption register"
            ]
          },
          {
            title: "Article 3 - SDAIA Oversight",
            description: "Saudi Data and AI Authority oversees compliance",
            order_no: 3,
            summary: "Understand SDAIA regulatory role",
            questions: [
              "Is SDAIA registration complete?",
              "Are reporting requirements understood?",
              "Is SDAIA accreditation obtained where required?"
            ],
            evidence_examples: [
              "SDAIA registration",
              "Reporting schedule",
              "Accreditation certificate"
            ]
          }
        ]
      },
      {
        title: "Chapter 2: Data Processing Principles",
        description: "Core principles governing personal data processing",
        order_no: 2,
        items: [
          {
            title: "Article 4 - Lawfulness of Processing",
            description: "Processing must be based on lawful grounds including explicit consent",
            order_no: 1,
            summary: "Ensure lawful processing basis",
            questions: [
              "Is explicit consent obtained where required?",
              "Are other lawful bases documented?",
              "Is consent withdrawal mechanism available?"
            ],
            evidence_examples: [
              "Consent management system",
              "Lawful basis register",
              "Consent withdrawal logs"
            ]
          },
          {
            title: "Article 5 - Purpose Limitation",
            description: "Data collected for specified, explicit, and legitimate purposes only",
            order_no: 2,
            summary: "Limit processing to stated purposes",
            questions: [
              "Are purposes clearly specified?",
              "Is secondary use restricted?",
              "Are purposes communicated to data subjects?"
            ],
            evidence_examples: [
              "Purpose specification documents",
              "Secondary use assessments",
              "Privacy notices"
            ]
          },
          {
            title: "Article 6 - Data Minimization",
            description: "Collect only data necessary for the specified purpose",
            order_no: 3,
            summary: "Minimize data collection",
            questions: [
              "Is data collection limited to necessity?",
              "Are unnecessary fields eliminated?",
              "Is periodic review conducted?"
            ],
            evidence_examples: [
              "Data minimization assessment",
              "Field necessity justification",
              "Review records"
            ]
          },
          {
            title: "Article 7 - Accuracy",
            description: "Data must be accurate, complete, and up to date",
            order_no: 4,
            summary: "Maintain data accuracy",
            questions: [
              "Are accuracy procedures implemented?",
              "Can data subjects update their data?",
              "Is inaccurate data corrected?"
            ],
            evidence_examples: [
              "Data quality procedures",
              "Update mechanisms",
              "Correction logs"
            ]
          },
          {
            title: "Article 8 - Storage Limitation",
            description: "Data retained only as long as necessary",
            order_no: 5,
            summary: "Implement retention limits",
            questions: [
              "Are retention periods defined?",
              "Is data securely deleted when expired?",
              "Are retention schedules enforced?"
            ],
            evidence_examples: [
              "Retention policy",
              "Deletion certificates",
              "Retention schedule"
            ]
          },
          {
            title: "Article 9 - Security",
            description: "Appropriate security measures to protect personal data",
            order_no: 6,
            summary: "Implement security safeguards",
            questions: [
              "Are technical security measures implemented?",
              "Are organizational measures in place?",
              "Is access controlled?"
            ],
            evidence_examples: [
              "Security policy",
              "Technical controls",
              "Access control matrix"
            ]
          }
        ]
      },
      {
        title: "Chapter 3: Data Subject Rights",
        description: "Rights of individuals under Saudi PDPL",
        order_no: 3,
        items: [
          {
            title: "Article 10 - Right to Know",
            description: "Data subjects have the right to know how their data is processed",
            order_no: 1,
            summary: "Provide processing information",
            questions: [
              "Are privacy notices provided in Arabic?",
              "Is processing information complete?",
              "Are data subjects informed before collection?"
            ],
            evidence_examples: [
              "Arabic privacy notices",
              "Information provision records",
              "Pre-collection disclosures"
            ]
          },
          {
            title: "Article 11 - Right of Access",
            description: "Data subjects can access their personal data",
            order_no: 2,
            summary: "Enable access requests",
            questions: [
              "Is access request process established?",
              "Are requests handled within 30 days?",
              "Is data provided in accessible format?"
            ],
            evidence_examples: [
              "Access request procedure",
              "Request handling logs",
              "Response templates"
            ]
          },
          {
            title: "Article 12 - Right to Rectification",
            description: "Data subjects can correct inaccurate data",
            order_no: 3,
            summary: "Enable data correction",
            questions: [
              "Can corrections be requested?",
              "Are corrections processed promptly?",
              "Are third parties notified?"
            ],
            evidence_examples: [
              "Rectification procedure",
              "Correction logs",
              "Third-party notifications"
            ]
          },
          {
            title: "Article 13 - Right to Erasure",
            description: "Data subjects can request deletion of their data",
            order_no: 4,
            summary: "Enable data deletion",
            questions: [
              "Is erasure process established?",
              "Are deletion criteria clear?",
              "Is data deleted from all systems?"
            ],
            evidence_examples: [
              "Erasure procedure",
              "Deletion verification",
              "System deletion logs"
            ]
          },
          {
            title: "Article 14 - Right to Object",
            description: "Data subjects can object to certain processing",
            order_no: 5,
            summary: "Handle processing objections",
            questions: [
              "Can objections be submitted?",
              "Are objections assessed properly?",
              "Is processing stopped when valid?"
            ],
            evidence_examples: [
              "Objection procedure",
              "Assessment records",
              "Processing cessation logs"
            ]
          }
        ]
      },
      {
        title: "Chapter 4: Cross-Border Transfers",
        description: "Requirements for international data transfers",
        order_no: 4,
        items: [
          {
            title: "Article 15 - Transfer Restrictions",
            description: "Transfers outside Saudi Arabia require adequate protection",
            order_no: 1,
            summary: "Control international transfers",
            questions: [
              "Are cross-border transfers identified?",
              "Is adequate protection ensured?",
              "Are transfers documented?"
            ],
            evidence_examples: [
              "Transfer inventory",
              "Adequacy assessments",
              "Transfer documentation"
            ]
          },
          {
            title: "Article 16 - Adequacy Determinations",
            description: "Transfers to countries with adequate protection",
            order_no: 2,
            summary: "Assess destination adequacy",
            questions: [
              "Is SDAIA adequacy list followed?",
              "Are non-adequate transfers justified?",
              "Are alternative safeguards used?"
            ],
            evidence_examples: [
              "Adequacy assessments",
              "Transfer justifications",
              "Safeguard documentation"
            ]
          },
          {
            title: "Article 17 - Contractual Safeguards",
            description: "Standard contractual clauses for transfers",
            order_no: 3,
            summary: "Implement transfer contracts",
            questions: [
              "Are approved SCCs used?",
              "Are contracts comprehensive?",
              "Are contracts reviewed regularly?"
            ],
            evidence_examples: [
              "Signed SCCs",
              "Data transfer agreements",
              "Contract review records"
            ]
          }
        ]
      },
      {
        title: "Chapter 5: SDAIA AI Ethics Principles (2023)",
        description: "SDAIA ethical principles for AI systems",
        order_no: 5,
        items: [
          {
            title: "Article 18 - AI Fairness",
            description: "AI systems must be fair and avoid discrimination",
            order_no: 1,
            summary: "Ensure AI fairness",
            questions: [
              "Are fairness assessments conducted?",
              "Is bias testing performed?",
              "Are protected groups considered?"
            ],
            evidence_examples: [
              "Fairness assessment reports",
              "Bias testing results",
              "Protected group analysis"
            ]
          },
          {
            title: "Article 19 - AI Transparency",
            description: "AI decision-making must be transparent and explainable",
            order_no: 2,
            summary: "Maintain AI transparency",
            questions: [
              "Are AI decisions explainable?",
              "Is documentation maintained?",
              "Are users informed of AI use?"
            ],
            evidence_examples: [
              "Explainability documentation",
              "AI system records",
              "User disclosures"
            ]
          },
          {
            title: "Article 20 - AI Accountability",
            description: "Clear accountability for AI outcomes",
            order_no: 3,
            summary: "Establish AI accountability",
            questions: [
              "Is accountability assigned?",
              "Is governance structure defined?",
              "Is human oversight maintained?"
            ],
            evidence_examples: [
              "Accountability matrix",
              "Governance framework",
              "Oversight procedures"
            ]
          },
          {
            title: "Article 21 - AI Privacy",
            description: "AI must respect personal data privacy",
            order_no: 4,
            summary: "Protect privacy in AI",
            questions: [
              "Is privacy-by-design implemented?",
              "Is data minimization applied?",
              "Are PETs considered?"
            ],
            evidence_examples: [
              "Privacy impact assessments",
              "Data minimization for AI",
              "PET implementation"
            ]
          },
          {
            title: "Article 22 - AI Safety",
            description: "AI systems must be safe and secure",
            order_no: 5,
            summary: "Ensure AI safety",
            questions: [
              "Are safety assessments conducted?",
              "Are security measures implemented?",
              "Are failure modes addressed?"
            ],
            evidence_examples: [
              "Safety assessments",
              "Security documentation",
              "Failure mode analysis"
            ]
          }
        ]
      },
      {
        title: "Chapter 6: Generative AI Guidelines (2024)",
        description: "SDAIA guidelines for generative AI systems",
        order_no: 6,
        items: [
          {
            title: "Article 23 - GenAI Risk Assessment",
            description: "Generative AI requires comprehensive risk assessment",
            order_no: 1,
            summary: "Assess generative AI risks",
            questions: [
              "Are GenAI risks identified?",
              "Is risk assessment documented?",
              "Are mitigations implemented?"
            ],
            evidence_examples: [
              "GenAI risk assessment",
              "Risk register",
              "Mitigation documentation"
            ]
          },
          {
            title: "Article 24 - Content Authenticity",
            description: "AI-generated content must be identifiable",
            order_no: 2,
            summary: "Mark AI-generated content",
            questions: [
              "Is AI content labeled?",
              "Are watermarks/markers used?",
              "Is deepfake prevention addressed?"
            ],
            evidence_examples: [
              "Content labeling policy",
              "Watermarking implementation",
              "Deepfake prevention measures"
            ]
          },
          {
            title: "Article 25 - Training Data Governance",
            description: "Proper governance of AI training data",
            order_no: 3,
            summary: "Govern training data",
            questions: [
              "Is training data sourced legally?",
              "Is data quality assured?",
              "Are biases in training data addressed?"
            ],
            evidence_examples: [
              "Data sourcing documentation",
              "Data quality records",
              "Bias assessment for training data"
            ]
          },
          {
            title: "Article 26 - Human Oversight",
            description: "Maintain human oversight of generative AI",
            order_no: 4,
            summary: "Ensure human control over GenAI",
            questions: [
              "Is human review implemented?",
              "Can AI outputs be overridden?",
              "Is escalation process defined?"
            ],
            evidence_examples: [
              "Human review procedures",
              "Override mechanisms",
              "Escalation protocols"
            ]
          }
        ]
      },
      {
        title: "Chapter 7: Enforcement and Penalties",
        description: "SDAIA enforcement and penalties up to SAR 5M",
        order_no: 7,
        items: [
          {
            title: "Article 27 - SDAIA Accreditation",
            description: "Certain activities require SDAIA accreditation",
            order_no: 1,
            summary: "Obtain required accreditation",
            questions: [
              "Is SDAIA accreditation required?",
              "Is accreditation obtained?",
              "Is accreditation maintained current?"
            ],
            evidence_examples: [
              "Accreditation certificate",
              "Accreditation requirements checklist",
              "Renewal records"
            ]
          },
          {
            title: "Article 28 - Breach Notification",
            description: "Data breaches must be notified to SDAIA",
            order_no: 2,
            summary: "Implement breach notification",
            questions: [
              "Is breach detection in place?",
              "Can notification be made timely?",
              "Are affected individuals notified?"
            ],
            evidence_examples: [
              "Breach response plan",
              "Notification procedures",
              "Breach register"
            ]
          },
          {
            title: "Article 29 - Administrative Penalties",
            description: "Violations may result in fines up to SAR 5 million",
            order_no: 3,
            summary: "Understand penalty provisions",
            questions: [
              "Are penalty provisions understood?",
              "Are high-risk areas addressed?",
              "Is compliance budget adequate?"
            ],
            evidence_examples: [
              "Penalty risk assessment",
              "Compliance remediation plan",
              "Budget allocation"
            ]
          },
          {
            title: "Article 30 - Compliance Monitoring",
            description: "Ongoing compliance monitoring requirements",
            order_no: 4,
            summary: "Implement compliance monitoring",
            questions: [
              "Is compliance monitoring in place?",
              "Are audits conducted regularly?",
              "Are findings remediated?"
            ],
            evidence_examples: [
              "Monitoring procedures",
              "Audit reports",
              "Remediation records"
            ]
          }
        ]
      }
    ]
  }
};

// plugins/saudi-pdpl/index.ts
var plugin = createFrameworkPlugin({
  key: "saudi-pdpl",
  name: "Saudi Arabia Personal Data Protection Law",
  description: "Saudi Arabia PDPL and SDAIA AI governance compliance framework.",
  version: "1.0.0",
  author: "VerifyWise",
  template: template_default.framework,
  autoImport: true
});
var { metadata, install, uninstall, validateConfig, router } = plugin;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  install,
  metadata,
  router,
  uninstall,
  validateConfig
});
